{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xiaoyanli/opt/miniconda3/envs/cancer_immune/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "import torch\n",
    "import random\n",
    "import shutil\n",
    "import pickle\n",
    "import pprint\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import models, transforms\n",
    "from transformers import ViTFeatureExtractor, ViTModel, ViTImageProcessor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set loaded from patients_codes_set.pkl: {'0233', '0164', '0205', '0022', '0158', '0272', '0440', '0380', '0094', '0307', '0286', '0247', '0210', '0352', '0390', '0315', '0308', '0042', '0304', '0351', '0143', '0226', '0374', '0432', '0120', '0003', '0238', '0441', '0329', '0115', '0267', '0453', '0288', '0451', '0273', '0300', '0411', '0066', '0142', '0243', '0039', '0179', '0290', '0335', '0082', '0447', '0161', '0400', '0263', '0123', '0021', '0402', '0454', '0016', '0287', '0418', '0298', '0023'}\n"
     ]
    }
   ],
   "source": [
    "data_frame = pd.read_csv('oasis_cross-sectional.csv')\n",
    "data_frame.drop('Delay', axis=1, inplace=True)\n",
    "data_frame = data_frame.dropna()\n",
    "\n",
    "with open('patients_codes_set.pkl', 'rb') as f:\n",
    "    patients_codes_set = pickle.load(f)\n",
    "\n",
    "print(\"Set loaded from patients_codes_set.pkl:\", patients_codes_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_dataframe = pd.DataFrame(columns=['Type', 'model', 'MMSE MAE', 'MMSE MSE', 'MMSE R2', 'MMSE RMSE'])\n",
    "\n",
    "lr = 1e-6\n",
    "epochs = 501\n",
    "num = 400\n",
    "train_folder = './train_data'\n",
    "# test_folder = './test_data'\n",
    "test_folder = './train_data'\n",
    "\n",
    "if not os.path.exists('./comparison'+'/models'):\n",
    "    os.makedirs('./comparison'+'/models')\n",
    "\n",
    "if not os.path.exists('./comparison'+'/results'):\n",
    "    os.makedirs('./comparison'+'/results')\n",
    "\n",
    "if not os.path.exists('./comparison'+'/test'):\n",
    "    os.makedirs('./comparison'+'/test')\n",
    "\n",
    "if not os.path.exists('./models'):\n",
    "    os.makedirs('./models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folders: ['VeryMildDemented', 'ModerateDemented', 'MildDemented', 'NonDemented']\n"
     ]
    }
   ],
   "source": [
    "folders = os.listdir(train_folder)\n",
    "folders = [folder for folder in folders if os.path.isdir(train_folder + '/'+folder)]\n",
    "print(\"Folders:\", folders)\n",
    "\n",
    "index = []\n",
    "for i in range(len(folders)):\n",
    "    folder = folders[i]\n",
    "    if i == 0:\n",
    "        y = 1\n",
    "    elif i == 1:\n",
    "        y = 3\n",
    "    elif i == 2:\n",
    "        y = 2\n",
    "    else:\n",
    "        y = 0\n",
    "    for file in os.listdir(train_folder + '/' + folder):\n",
    "        index.append([train_folder + '/' + folder + '/' + file, y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_results(results, mode):\n",
    "    # adding MR1_1 results to the dataframe\n",
    "    mae_MMSE = mean_absolute_error(results['True MMSE'], results['Predicted MMSE'])\n",
    "    # print(f'MMSE MAE: {mae_MMSE}')\n",
    "    # mae_CDR = mean_absolute_error(results['True CDR'], results['Predicted CDR'])\n",
    "    # # print(f'CDR MAE: {mae_CDR}')\n",
    "    # mae_SES = mean_absolute_error(results['True SES'], results['Predicted SES'])\n",
    "    # print(f'SES MAE: {mae_SES}')\n",
    "\n",
    "    mse_MMSE = mean_squared_error(results['True MMSE'], results['Predicted MMSE'])\n",
    "    # print(f'MMSE MSE: {mse_MMSE}')\n",
    "    # mse_CDR = mean_squared_error(results['True CDR'], results['Predicted CDR'])\n",
    "    # # print(f'CDR MSE: {mse_CDR}')\n",
    "    # mse_SES = mean_squared_error(results['True SES'], results['Predicted SES'])\n",
    "    # print(f'SES MSE: {mse_SES}')\n",
    "\n",
    "    r2_MMSE = r2_score(results['True MMSE'], results['Predicted MMSE'])\n",
    "    # print(f'MMSE R2: {r2_MMSE}')\n",
    "    # r2_CDR = r2_score(results['True CDR'], results['Predicted CDR'])\n",
    "    # # print(f'CDR R2: {r2_CDR}')\n",
    "    # r2_SES = r2_score(results['True SES'], results['Predicted SES'])\n",
    "    # print(f'SES R2: {r2_SES}')\n",
    "\n",
    "    rmse_MMSE = root_mean_squared_error(results['True MMSE'], results['Predicted MMSE'])\n",
    "    # print(f'MMSE RMSE: {rmse_MMSE}')\n",
    "    # rmse_CDR = root_mean_squared_error(results['True CDR'], results['Predicted CDR'])\n",
    "    # # print(f'CDR RMSE: {rmse_CDR}')\n",
    "    # rmse_SES = root_mean_squared_error(results['True SES'], results['Predicted SES'])\n",
    "    # print(f'SES RMSE: {rmse_SES}')\n",
    "\n",
    "    # new_data = pd.DataFrame([{'Type': 'Regression', 'model': mode, 'MMSE MAE': mae_MMSE, 'CDR MAE': mae_CDR, 'SES MAE': mae_SES, 'MMSE MSE': mse_MMSE, 'CDR MSE': mse_CDR, 'SES MSE': mse_SES, 'MMSE R2': r2_MMSE, 'CDR R2': r2_CDR, 'SES R2': r2_SES, 'MMSE RMSE': rmse_MMSE, 'CDR RMSE': rmse_CDR, 'SES RMSE': rmse_SES}])\n",
    "    \n",
    "    new_data = pd.DataFrame([{'Type': 'Regression', 'model': mode, 'MMSE MAE': mae_MMSE, 'MMSE MSE': mse_MMSE, 'MMSE R2': r2_MMSE, 'MMSE RMSE': rmse_MMSE}])\n",
    "\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "# regression model\n",
    "# Initialize the feature extractor and the model\n",
    "feature_extractor = ViTImageProcessor.from_pretrained('google/vit-base-patch16-224-in21k')\n",
    "vit_model = ViTModel.from_pretrained('google/vit-base-patch16-224-in21k')\n",
    "\n",
    "# Freeze the ViT model parameters\n",
    "for param in vit_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "class CombinedModel(nn.Module):\n",
    "    def __init__(self, vit_model):\n",
    "        super(CombinedModel, self).__init__()\n",
    "        self.vit_model = vit_model\n",
    "        self.linear_layer = nn.Linear(vit_model.config.hidden_size, 3)\n",
    "        self.linear_layer.weight.data.normal_(mean=0.0, std=0.02)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.out_1 = nn.Linear(8, 5)\n",
    "        self.out_1.weight.data.normal_(mean=0.0, std=0.02)\n",
    "        self.out_2 = nn.Linear(5, 1)\n",
    "        self.out_2.weight.data.normal_(mean=0.0, std=0.02)\n",
    "\n",
    "    def forward(self, inputs, x):\n",
    "        # Preprocess the input tensor\n",
    "        inputs = inputs.mean(dim=0, keepdim=True).repeat(3, 1, 1)\n",
    "        inputs = feature_extractor(images=inputs, return_tensors=\"pt\")\n",
    "        outputs = self.vit_model(**inputs)\n",
    "        last_hidden_state = outputs.last_hidden_state\n",
    "        pooled_output = last_hidden_state.mean(dim=1)\n",
    "        final_output = self.linear_layer(pooled_output)\n",
    "        # print(final_output.shape, x.shape)\n",
    "        final_output = torch.cat((final_output, x), 1)\n",
    "        # print(final_output.shape)\n",
    "        final_output = self.relu(final_output)\n",
    "        final_output = self.out_1(final_output)\n",
    "        final_output = self.relu(final_output)\n",
    "        final_output = self.out_2(final_output)\n",
    "        return final_output\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Device:', device)\n",
    "model = CombinedModel(vit_model).to(device)\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode_list = ['MR1_1', 'MR1_2', 'MR1_3', 'MR1_4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "It looks like you are trying to rescale already rescaled images. If the input images have pixel values between 0 and 1, set `do_rescale=False` to avoid rescaling them again.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training MR1_1 model\n",
      "Epoch 0 loss: 78701.53210449219\n",
      "Epoch 100 loss: 74757.78858947754\n",
      "Epoch 200 loss: 69160.09353637695\n",
      "Epoch 300 loss: 70660.8083190918\n",
      "Epoch 400 loss: 74302.4275970459\n",
      "Epoch 500 loss: 76706.56958007812\n",
      "Model saved to models/MR1_1_reg.pth\n",
      "Training MR1_2 model\n",
      "Epoch 0 loss: 90190.17953491211\n",
      "Epoch 100 loss: 76625.70092773438\n",
      "Epoch 200 loss: 72214.13122558594\n",
      "Epoch 300 loss: 83002.19458007812\n",
      "Epoch 400 loss: 73933.3599243164\n",
      "Epoch 500 loss: 77370.93539428711\n",
      "Model saved to models/MR1_2_reg.pth\n",
      "Training MR1_3 model\n",
      "Epoch 0 loss: 68644.83992004395\n",
      "Epoch 100 loss: 74019.81463623047\n",
      "Epoch 200 loss: 73348.26153564453\n",
      "Epoch 300 loss: 74228.5511932373\n",
      "Epoch 400 loss: 86622.53573608398\n",
      "Epoch 500 loss: 73536.5950012207\n",
      "Model saved to models/MR1_3_reg.pth\n",
      "Training MR1_4 model\n",
      "Epoch 0 loss: 68882.3466796875\n",
      "Epoch 100 loss: 70684.30493164062\n",
      "Epoch 200 loss: 86320.25775146484\n",
      "Epoch 300 loss: 73352.9733581543\n",
      "Epoch 400 loss: 63945.5680847168\n",
      "Epoch 500 loss: 72364.41641235352\n",
      "Model saved to models/MR1_4_reg.pth\n"
     ]
    }
   ],
   "source": [
    "# regression models\n",
    "\n",
    "for i in range(len(mode_list)):\n",
    "    model = CombinedModel(vit_model).to(device)\n",
    "    model_load_path = 'models/MR1_1_reg.pth'\n",
    "    # model.load_state_dict(torch.load(model_load_path))\n",
    "\n",
    "    seed = 42\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.use_deterministic_algorithms(True)\n",
    "\n",
    "    model = CombinedModel(vit_model).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    mode = mode_list[i]\n",
    "    print(f\"Training {mode} model\")\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        results = [['code', 'Predicted MMSE', 'True MMSE']]\n",
    "        for i in range(num):\n",
    "            random_index = random.randint(0, len(index)-1)\n",
    "            filename = index[random_index][0]\n",
    "            if mode in filename:\n",
    "                data = np.load(index[random_index][0])\n",
    "                data = data/255\n",
    "                label = index[random_index][1]\n",
    "                code = index[random_index][0][-14:-10]\n",
    "                x = data_frame[data_frame['ID'].str.contains(code)][['Age', 'Educ', 'eTIV', 'nWBV', 'ASF']].to_numpy()\n",
    "                x[:, 0] = (x[:, 0] - 18) / (96 - 18)\n",
    "                x[:, 1] = (x[:, 1] - 5) / (5 - 1)\n",
    "                x[:, 2] = (x[:, 2] - 1123) / (1992 - 1123)\n",
    "                x[:, 3] = (x[:, 3] - 0.644) / (0.893 - 0.644)\n",
    "                x[:, 4] = (x[:, 4] - 0.881) / (1.563 - 0.881)\n",
    "                if code not in patients_codes_set:\n",
    "                    x = np.zeros((1, 5))\n",
    "                x = torch.tensor(x).float()\n",
    "                y = data_frame[data_frame['ID'].str.contains(code)]['MMSE'].to_numpy()\n",
    "                if len(y) == 0:\n",
    "                    y = np.mean(data_frame['MMSE'])\n",
    "                    y = np.array([y])\n",
    "                # print(y)\n",
    "                model.train()\n",
    "                optimizer.zero_grad()\n",
    "                input_tensor = torch.clamp(torch.tensor(data), 0, 1)\n",
    "                outputs = model(input_tensor, x)\n",
    "                loss = criterion(outputs, torch.tensor(y).float())\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                running_loss += loss.item()\n",
    "                results.append([code, outputs[0][0].detach().numpy(), y[0]])\n",
    "        if epoch % 100 ==0:\n",
    "            print(f'Epoch {epoch} loss: {running_loss}')\n",
    "\n",
    "    # convert the results to a numpy array\n",
    "    results = pd.DataFrame(results[1:], columns=results[0])\n",
    "    results.to_csv('results/'+mode+'_'+'results_reg.csv', index=False)\n",
    "\n",
    "    model_save_path = 'models/'+mode+'_'+'reg.pth'\n",
    "    torch.save(model.state_dict(), model_save_path)\n",
    "    print(f\"Model saved to {model_save_path}\")\n",
    "\n",
    "    new_data = calculate_results(results, mode)\n",
    "    regression_dataframe = pd.concat([regression_dataframe, new_data], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_dataframe.to_csv('results/regression_results.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cancer_immune_jupyter",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
