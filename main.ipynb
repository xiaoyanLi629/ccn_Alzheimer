{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import torch\n",
    "import random\n",
    "import shutil\n",
    "import pickle\n",
    "import pprint\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import models, transforms\n",
    "from transformers import ViTFeatureExtractor, ViTModel, ViTImageProcessor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import root_mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_empty(channel):\n",
    "    return np.sum(channel) == 0\n",
    "\n",
    "def map_values(value, old_min, old_max, new_min, new_max):\n",
    "    return int(new_min + (value - old_min) * (new_max - new_min) / (old_max - old_min))\n",
    "\n",
    "vectorized_map_values = np.vectorize(map_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to the folder\n",
    "new_min = 0\n",
    "new_max = 71\n",
    "mode_list = ['MR1_1', 'MR1_2', 'MR1_3', 'MR1_4']\n",
    "data_names = []\n",
    "\n",
    "for mode in mode_list:\n",
    "    for folder in os.listdir('./original_data'):\n",
    "        if os.path.isdir('./original_data' + '/'+folder):\n",
    "            folder_path = './original_data'+'/'+folder\n",
    "            # Get a list of all PNG files in the folder\n",
    "            files = [f for f in os.listdir(folder_path) if f.endswith('.png')]\n",
    "            files_code = list(set([f[5:9] for f in files]))\n",
    "            for code in files_code:\n",
    "                data = np.zeros((72, 232, 465))\n",
    "                temp_dict = {}\n",
    "                temp_list = []\n",
    "                file_names = []\n",
    "                for file in files:\n",
    "                    if code == file[5:9] and mode in file:\n",
    "                        index = 0\n",
    "                        if len(file) == 33:\n",
    "                            index = int(file[26:29])\n",
    "                        elif len(file) == 32:\n",
    "                            index = int(file[26:28])\n",
    "                        temp_list.append(index)\n",
    "                        file_names.append(file)\n",
    "                # temp_list.sort()\n",
    "                if len(temp_list) == 0:\n",
    "                    continue\n",
    "                # print(file_names)\n",
    "                old_min = min(temp_list)\n",
    "                old_max = max(temp_list)\n",
    "                new_values = vectorized_map_values(np.array(temp_list), old_min, old_max, new_min, new_max)\n",
    "                for i in range(len(new_values)):\n",
    "                    temp_dict[new_values[i]] = file_names[i]\n",
    "                for key in sorted(temp_dict.keys()):\n",
    "                    data[key, :, :] = np.array(Image.open(os.path.join(folder_path, temp_dict[key])))[:, :, 0]\n",
    "\n",
    "                # Find the indices of the channels with data\n",
    "                data_indices = [i for i in range(data.shape[0]) if not is_empty(data[i])]\n",
    "\n",
    "                # Fill the empty channels with gradient\n",
    "                for i in range(data.shape[0]):\n",
    "                    if is_empty(data[i]):\n",
    "                        # Find the nearest channels with data before and after the empty channel\n",
    "                        before = max([idx for idx in data_indices if idx < i], default=None)\n",
    "                        after = min([idx for idx in data_indices if idx > i], default=None)\n",
    "                        \n",
    "                        if before is not None and after is not None:\n",
    "                            # Interpolate between the before and after channels\n",
    "                            gradient = (data[after] - data[before]) / (after - before)\n",
    "                            data[i] = data[before] + gradient * (i - before)\n",
    "                        elif before is not None:\n",
    "                            # If there is no after channel, use the before channel\n",
    "                            data[i] = data[before]\n",
    "                        elif after is not None:\n",
    "                            # If there is no before channel, use the after channel\n",
    "                            data[i] = data[after]\n",
    "\n",
    "                file_name = os.path.join('combined_data', folder, code+'_'+mode+'.npy')\n",
    "                data_names.append(file_name)\n",
    "                np.save(file_name, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "milddemented = [ele[27:31] for ele in data_names if 'MildDemented' in ele and 'VeryMildDemented' not in ele]\n",
    "moderatedemented = [ele[31:35] for ele in data_names if 'ModerateDemented' in ele]\n",
    "nonedemented = [ele[26:30] for ele in data_names if 'NonDemented' in ele]\n",
    "verymildlydemented = [ele[31:35] for ele in data_names if 'VeryMildDemented' in ele]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame = pd.read_csv('oasis_cross-sectional.csv')\n",
    "data_frame.drop('Delay', axis=1, inplace=True)\n",
    "data_frame = data_frame.dropna()\n",
    "\n",
    "records_codes = [ele[5:9] for ele in list(data_frame['ID'])]\n",
    "records_codes_set = set(records_codes)\n",
    "files_codes = [ele[31:35] for ele in data_names]\n",
    "files_codes_set = set(files_codes)\n",
    "\n",
    "patients_codes_set = records_codes_set.intersection(files_codes_set)\n",
    "# save the data of the patients\n",
    "with open('patients_codes_set.pkl', 'wb') as f:\n",
    "    pickle.dump(patients_codes_set, f)\n",
    "\n",
    "print(\"Set saved to patients_codes_set.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('patients_codes_set.pkl', 'rb') as f:\n",
    "    patients_codes_set = pickle.load(f)\n",
    "\n",
    "print(\"Set loaded from patients_codes_set.pkl:\", patients_codes_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame[:2]\n",
    "len(patients_codes_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose test items\n",
    "# Set the random seed for reproducibility\n",
    "with open('patients_codes_set.pkl', 'rb') as f:\n",
    "    patients_codes_set = pickle.load(f)\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "# Define the folders\n",
    "folders = ['MildDemented', 'ModerateDemented', 'NonDemented', 'VeryMildDemented']\n",
    "base_path = 'test_data'  # Replace with the path to your data\n",
    "\n",
    "# Function to randomly select and delete files\n",
    "def select_and_delete_files(folder_path, percentage):\n",
    "    # List all files in the folder\n",
    "    files = [f for f in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, f))]\n",
    "    \n",
    "    # Calculate the number of files to keep\n",
    "    num_files_to_keep = int(len(files) * percentage)\n",
    "    \n",
    "    # Randomly select files to keep\n",
    "    files_to_keep = random.sample(files, num_files_to_keep)\n",
    "    \n",
    "    # Delete the remaining files\n",
    "    for file in files:\n",
    "        # print(file)\n",
    "        if file not in files_to_keep and file[:4] in patients_codes_set:\n",
    "            os.remove(os.path.join(folder_path, file))\n",
    "            # print(f\"Deleted: {os.path.join(folder_path, file)}\")\n",
    "\n",
    "# # Process each folder\n",
    "for folder in folders:\n",
    "    folder_path = os.path.join(base_path, folder)\n",
    "    select_and_delete_files(folder_path, 0.8)\n",
    "\n",
    "print(\"Process complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process complete.\n"
     ]
    }
   ],
   "source": [
    "# choose test items\n",
    "# Set the random seed for reproducibility\n",
    "with open('patients_codes_set.pkl', 'rb') as f:\n",
    "    patients_codes_set = pickle.load(f)\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "# Define the folders\n",
    "folders = ['MildDemented', 'ModerateDemented', 'NonDemented', 'VeryMildDemented']\n",
    "base_path = 'train_data'  # Replace with the path to your data\n",
    "\n",
    "# Function to randomly select and delete files\n",
    "def select_and_delete_files(folder_path, percentage):\n",
    "    # List all files in the folder\n",
    "    files = [f for f in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, f))]\n",
    "    \n",
    "    # Calculate the number of files to keep\n",
    "    num_files_to_keep = int(len(files) * percentage)\n",
    "    \n",
    "    # Randomly select files to keep\n",
    "    files_to_keep = random.sample(files, num_files_to_keep)\n",
    "    \n",
    "    # Delete the remaining files\n",
    "    for file in files:\n",
    "        # print(file)\n",
    "        if file not in files_to_keep or file[:4] in patients_codes_set:\n",
    "            os.remove(os.path.join(folder_path, file))\n",
    "            # print(f\"Deleted: {os.path.join(folder_path, file)}\")\n",
    "\n",
    "# # Process each folder\n",
    "for folder in folders:\n",
    "    folder_path = os.path.join(base_path, folder)\n",
    "    select_and_delete_files(folder_path, 1)\n",
    "\n",
    "print(\"Process complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regression model\n",
    "# Initialize the feature extractor and the model\n",
    "feature_extractor = ViTImageProcessor.from_pretrained('google/vit-base-patch16-224-in21k')\n",
    "vit_model = ViTModel.from_pretrained('google/vit-base-patch16-224-in21k')\n",
    "\n",
    "# Freeze the ViT model parameters\n",
    "for param in vit_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "class CombinedModel(nn.Module):\n",
    "    def __init__(self, vit_model):\n",
    "        super(CombinedModel, self).__init__()\n",
    "        self.vit_model = vit_model\n",
    "        self.linear_layer = nn.Linear(vit_model.config.hidden_size, 3)\n",
    "        self.linear_layer.weight.data.normal_(mean=0.0, std=0.02)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.out_1 = nn.Linear(8, 5)\n",
    "        self.out_1.weight.data.normal_(mean=0.0, std=0.02)\n",
    "        self.out_2 = nn.Linear(5, 3)\n",
    "        self.out_2.weight.data.normal_(mean=0.0, std=0.02)\n",
    "\n",
    "    def forward(self, inputs, x):\n",
    "        # Preprocess the input tensor\n",
    "        inputs = inputs.mean(dim=0, keepdim=True).repeat(3, 1, 1)\n",
    "        inputs = feature_extractor(images=inputs, return_tensors=\"pt\")\n",
    "        outputs = self.vit_model(**inputs)\n",
    "        last_hidden_state = outputs.last_hidden_state\n",
    "        pooled_output = last_hidden_state.mean(dim=1)\n",
    "        final_output = self.linear_layer(pooled_output)\n",
    "        # print(final_output.shape, x.shape)\n",
    "        final_output = torch.cat((final_output, x), 1)\n",
    "        # print(final_output.shape)\n",
    "        final_output = self.relu(final_output)\n",
    "        final_output = self.out_1(final_output)\n",
    "        final_output = self.relu(final_output)\n",
    "        final_output = self.out_2(final_output)\n",
    "        return final_output\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Device:', device)\n",
    "model = CombinedModel(vit_model).to(device)\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.MSELoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_dataframe = pd.DataFrame(columns=['Type', 'model', 'MMSE MAE', 'CDR MAE', 'SES MAE', 'MMSE MSE', 'CDR MSE', 'SES MSE', 'MMSE R2', 'CDR R2', 'SES R2', 'MMSE RMSE', 'CDR RMSE', 'SES RMSE'])\n",
    "\n",
    "test_regression_dataframe = pd.DataFrame(columns=['Type', 'model', 'MMSE MAE', 'CDR MAE', 'SES MAE', 'MMSE MSE', 'CDR MSE', 'SES MSE', 'MMSE R2', 'CDR R2', 'SES R2', 'MMSE RMSE', 'CDR RMSE', 'SES RMSE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regression MR1_1\n",
    "model = CombinedModel(vit_model).to(device)\n",
    "model_load_path = 'models/MR1_1_reg.pth'\n",
    "model.load_state_dict(torch.load(model_load_path))\n",
    "\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.use_deterministic_algorithms(True)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "mode_list = ['MR1_1', 'MR1_2', 'MR1_3', 'MR1_4']\n",
    "mode = 'MR1_1'\n",
    "\n",
    "for epoch in range(10001):\n",
    "    running_loss = 0.0\n",
    "    results = []\n",
    "    for folder in os.listdir('./combined_data'):\n",
    "        if os.path.isdir('./combined_data' + '/'+folder):\n",
    "            folder_path = './combined_data'+'/'+folder\n",
    "            files = [f for f in os.listdir(folder_path) if f.endswith('.npy') and mode in f and f[0:4] in patients_codes_set]\n",
    "            if folder == 'NonDemented':\n",
    "                label = 0\n",
    "            elif folder == 'VeryMildDemented':\n",
    "                label = 1\n",
    "            elif folder == 'MildDemented':\n",
    "                label = 2\n",
    "            elif folder == 'ModerateDemented':\n",
    "                label = 3\n",
    "            for f in files :\n",
    "                data = np.load(os.path.join(folder_path, f))\n",
    "                code = f[0:4]\n",
    "                x = data_frame[data_frame['ID'].str.contains(code)][['Age', 'Educ', 'eTIV', 'nWBV', 'ASF']].to_numpy()\n",
    "                x = torch.tensor(x).float()\n",
    "                y = data_frame[data_frame['ID'].str.contains(code)][['MMSE', 'CDR', 'SES']].to_numpy()\n",
    "                model.train()\n",
    "                optimizer.zero_grad()\n",
    "                input_tensor = torch.clamp(torch.tensor(data), 0, 1)\n",
    "                outputs = model(input_tensor, x)\n",
    "                loss = criterion(outputs, torch.tensor(y).float())\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                running_loss += loss.item()\n",
    "                results.append((outputs.detach().numpy(), y))\n",
    "    if epoch % 50 ==0:\n",
    "        print(f'Epoch {epoch} loss: {running_loss}')\n",
    "\n",
    "# convert the results to a numpy array\n",
    "results = np.array(results).reshape(-1, 6)\n",
    "results = pd.DataFrame(results, columns=['Predicted MMSE', 'Predicted CDR', 'Predicted SES', 'True MMSE', 'True CDR', 'True SES'])\n",
    "results.to_csv('results/'+mode+'_'+'results_reg.csv', index=False)\n",
    "\n",
    "model_save_path = 'models/'+mode+'_'+'reg.pth'\n",
    "torch.save(model.state_dict(), model_save_path)\n",
    "print(f\"Model saved to {model_save_path}\")\n",
    "\n",
    "model_test = CombinedModel(vit_model)\n",
    "\n",
    "# Load the model state\n",
    "# model_load_path = model_save_path\n",
    "# model.load_state_dict(torch.load(model_load_path))\n",
    "# model.eval()  # Set the model to evaluation mode\n",
    "# print(f\"Model loaded from {model_load_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = 'MR1_1'\n",
    "results = pd.read_csv('results/'+mode+'_'+'results_reg.csv')\n",
    "\n",
    "# adding MR1_1 results to the dataframe\n",
    "mae_MMSE = mean_absolute_error(results['True MMSE'], results['Predicted MMSE'])\n",
    "# print(f'MMSE MAE: {mae_MMSE}')\n",
    "mae_CDR = mean_absolute_error(results['True CDR'], results['Predicted CDR'])\n",
    "# print(f'CDR MAE: {mae_CDR}')\n",
    "mae_SES = mean_absolute_error(results['True SES'], results['Predicted SES'])\n",
    "# print(f'SES MAE: {mae_SES}')\n",
    "\n",
    "mse_MMSE = mean_squared_error(results['True MMSE'], results['Predicted MMSE'])\n",
    "# print(f'MMSE MSE: {mse_MMSE}')\n",
    "mse_CDR = mean_squared_error(results['True CDR'], results['Predicted CDR'])\n",
    "# print(f'CDR MSE: {mse_CDR}')\n",
    "mse_SES = mean_squared_error(results['True SES'], results['Predicted SES'])\n",
    "# print(f'SES MSE: {mse_SES}')\n",
    "\n",
    "r2_MMSE = r2_score(results['True MMSE'], results['Predicted MMSE'])\n",
    "# print(f'MMSE R2: {r2_MMSE}')\n",
    "r2_CDR = r2_score(results['True CDR'], results['Predicted CDR'])\n",
    "# print(f'CDR R2: {r2_CDR}')\n",
    "r2_SES = r2_score(results['True SES'], results['Predicted SES'])\n",
    "# print(f'SES R2: {r2_SES}')\n",
    "\n",
    "rmse_MMSE = root_mean_squared_error(results['True MMSE'], results['Predicted MMSE'])\n",
    "# print(f'MMSE RMSE: {rmse_MMSE}')\n",
    "rmse_CDR = root_mean_squared_error(results['True CDR'], results['Predicted CDR'])\n",
    "# print(f'CDR RMSE: {rmse_CDR}')\n",
    "rmse_SES = root_mean_squared_error(results['True SES'], results['Predicted SES'])\n",
    "# print(f'SES RMSE: {rmse_SES}')\n",
    "\n",
    "new_data = pd.DataFrame([{'Type': 'Regression', 'model': 'MR1_1', 'MMSE MAE': mae_MMSE, 'CDR MAE': mae_CDR, 'SES MAE': mae_SES, 'MMSE MSE': mse_MMSE, 'CDR MSE': mse_CDR, 'SES MSE': mse_SES, 'MMSE R2': r2_MMSE, 'CDR R2': r2_CDR, 'SES R2': r2_SES, 'MMSE RMSE': rmse_MMSE, 'CDR RMSE': rmse_CDR, 'SES RMSE': rmse_SES}])\n",
    "\n",
    "regression_dataframe = pd.concat([regression_dataframe, new_data], ignore_index=True)\n",
    "\n",
    "new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regression MR1_1 test\n",
    "model = CombinedModel(vit_model).to(device)\n",
    "model_load_path = 'models/MR1_1_reg.pth'\n",
    "model.load_state_dict(torch.load(model_load_path))\n",
    "\n",
    "running_loss = 0.0\n",
    "results = []\n",
    "for folder in os.listdir('./test'):\n",
    "    if os.path.isdir('./test' + '/'+folder):\n",
    "        folder_path = './test'+'/'+folder\n",
    "        files = [f for f in os.listdir(folder_path) if f.endswith('.npy') and mode in f and f[0:4] in patients_codes_set]\n",
    "        if folder == 'NonDemented':\n",
    "            label = 0\n",
    "        elif folder == 'VeryMildDemented':\n",
    "            label = 1\n",
    "        elif folder == 'MildDemented':\n",
    "            label = 2\n",
    "        elif folder == 'ModerateDemented':\n",
    "            label = 3\n",
    "        for f in files :\n",
    "            data = np.load(os.path.join(folder_path, f))\n",
    "            code = f[0:4]\n",
    "            x = data_frame[data_frame['ID'].str.contains(code)][['Age', 'Educ', 'eTIV', 'nWBV', 'ASF']].to_numpy()\n",
    "            x = torch.tensor(x).float()\n",
    "            y = data_frame[data_frame['ID'].str.contains(code)][['MMSE', 'CDR', 'SES']].to_numpy()\n",
    "            model.eval()\n",
    "            input_tensor = torch.clamp(torch.tensor(data), 0, 1)\n",
    "            outputs = model(input_tensor, x)\n",
    "            loss = criterion(outputs, torch.tensor(y).float())\n",
    "            running_loss += loss.item()\n",
    "            results.append((outputs.detach().numpy(), y))\n",
    "results = np.array(results).reshape(-1, 6)\n",
    "results = pd.DataFrame(results, columns=['Predicted MMSE', 'Predicted CDR', 'Predicted SES', 'True MMSE', 'True CDR', 'True SES'])\n",
    "\n",
    "results.to_csv('test_results/'+mode+'_'+'results_reg.csv', index=False)\n",
    "\n",
    "# adding MR1_2 results to the dataframe\n",
    "\n",
    "mae_MMSE = mean_absolute_error(results['True MMSE'], results['Predicted MMSE'])\n",
    "# print(f'MMSE MAE: {mae_MMSE}')\n",
    "mae_CDR = mean_absolute_error(results['True CDR'], results['Predicted CDR'])\n",
    "# print(f'CDR MAE: {mae_CDR}')\n",
    "mae_SES = mean_absolute_error(results['True SES'], results['Predicted SES'])\n",
    "# print(f'SES MAE: {mae_SES}')\n",
    "\n",
    "mse_MMSE = mean_squared_error(results['True MMSE'], results['Predicted MMSE'])\n",
    "# print(f'MMSE MSE: {mse_MMSE}')\n",
    "mse_CDR = mean_squared_error(results['True CDR'], results['Predicted CDR'])\n",
    "# print(f'CDR MSE: {mse_CDR}')\n",
    "mse_SES = mean_squared_error(results['True SES'], results['Predicted SES'])\n",
    "# print(f'SES MSE: {mse_SES}')\n",
    "\n",
    "r2_MMSE = r2_score(results['True MMSE'], results['Predicted MMSE'])\n",
    "# print(f'MMSE R2: {r2_MMSE}')\n",
    "r2_CDR = r2_score(results['True CDR'], results['Predicted CDR'])\n",
    "# print(f'CDR R2: {r2_CDR}')\n",
    "r2_SES = r2_score(results['True SES'], results['Predicted SES'])\n",
    "# print(f'SES R2: {r2_SES}')\n",
    "\n",
    "rmse_MMSE = root_mean_squared_error(results['True MMSE'], results['Predicted MMSE'])\n",
    "# print(f'MMSE RMSE: {rmse_MMSE}')\n",
    "rmse_CDR = root_mean_squared_error(results['True CDR'], results['Predicted CDR'])\n",
    "# print(f'CDR RMSE: {rmse_CDR}')\n",
    "rmse_SES = root_mean_squared_error(results['True SES'], results['Predicted SES'])\n",
    "# print(f'SES RMSE: {rmse_SES}')\n",
    "\n",
    "new_data = pd.DataFrame([{'Type': 'Regression', 'model': 'MR1_1', 'MMSE MAE': mae_MMSE, 'CDR MAE': mae_CDR, 'SES MAE': mae_SES, 'MMSE MSE': mse_MMSE, 'CDR MSE': mse_CDR, 'SES MSE': mse_SES, 'MMSE R2': r2_MMSE, 'CDR R2': r2_CDR, 'SES R2': r2_SES, 'MMSE RMSE': rmse_MMSE, 'CDR RMSE': rmse_CDR, 'SES RMSE': rmse_SES}])\n",
    "\n",
    "test_regression_dataframe = pd.concat([test_regression_dataframe, new_data], ignore_index=True)\n",
    "\n",
    "test_regression_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regression MR1_2\n",
    "model = CombinedModel(vit_model).to(device)\n",
    "model_load_path = 'models/MR1_1_reg.pth'\n",
    "model.load_state_dict(torch.load(model_load_path))\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.use_deterministic_algorithms(True)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "mode_list = ['MR1_1', 'MR1_2', 'MR1_3', 'MR1_4']\n",
    "mode = 'MR1_2'\n",
    "\n",
    "for epoch in range(501):\n",
    "    running_loss = 0.0\n",
    "    results = []\n",
    "    for folder in os.listdir('./combined_data'):\n",
    "        if os.path.isdir('./combined_data' + '/'+folder):\n",
    "            folder_path = './combined_data'+'/'+folder\n",
    "            files = [f for f in os.listdir(folder_path) if f.endswith('.npy') and mode in f and f[0:4] in patients_codes_set]\n",
    "            if folder == 'NonDemented':\n",
    "                label = 0\n",
    "            elif folder == 'VeryMildDemented':\n",
    "                label = 1\n",
    "            elif folder == 'MildDemented':\n",
    "                label = 2\n",
    "            elif folder == 'ModerateDemented':\n",
    "                label = 3\n",
    "            for f in files :\n",
    "                data = np.load(os.path.join(folder_path, f))\n",
    "                code = f[0:4]\n",
    "                x = data_frame[data_frame['ID'].str.contains(code)][['Age', 'Educ', 'eTIV', 'nWBV', 'ASF']].to_numpy()\n",
    "                x = torch.tensor(x).float()\n",
    "                y = data_frame[data_frame['ID'].str.contains(code)][['MMSE', 'CDR', 'SES']].to_numpy()\n",
    "                model.train()\n",
    "                optimizer.zero_grad()\n",
    "                input_tensor = torch.clamp(torch.tensor(data), 0, 1)\n",
    "                outputs = model(input_tensor, x)\n",
    "                loss = criterion(outputs, torch.tensor(y).float())\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                running_loss += loss.item()\n",
    "                results.append((outputs.detach().numpy(), y))\n",
    "    if epoch == 500:\n",
    "        print(f'Epoch {epoch} loss: {running_loss}')\n",
    "\n",
    "# convert the results to a numpy array\n",
    "results = np.array(results).reshape(-1, 6)\n",
    "results = pd.DataFrame(results, columns=['Predicted MMSE', 'Predicted CDR', 'Predicted SES', 'True MMSE', 'True CDR', 'True SES'])\n",
    "results.to_csv('results/'+mode+'_'+'results_reg.csv', index=False)\n",
    "\n",
    "model_save_path = 'models/'+mode+'_'+'reg.pth'\n",
    "torch.save(model.state_dict(), model_save_path)\n",
    "print(f\"Model saved to {model_save_path}\")\n",
    "\n",
    "model_test = CombinedModel(vit_model)\n",
    "\n",
    "# Load the model state\n",
    "# model_load_path = model_save_path\n",
    "# model.load_state_dict(torch.load(model_load_path))\n",
    "# model.eval()  # Set the model to evaluation mode\n",
    "# print(f\"Model loaded from {model_load_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding MR1_2 results to the dataframe\n",
    "\n",
    "mae_MMSE = mean_absolute_error(results['True MMSE'], results['Predicted MMSE'])\n",
    "# print(f'MMSE MAE: {mae_MMSE}')\n",
    "mae_CDR = mean_absolute_error(results['True CDR'], results['Predicted CDR'])\n",
    "# print(f'CDR MAE: {mae_CDR}')\n",
    "mae_SES = mean_absolute_error(results['True SES'], results['Predicted SES'])\n",
    "# print(f'SES MAE: {mae_SES}')\n",
    "\n",
    "mse_MMSE = mean_squared_error(results['True MMSE'], results['Predicted MMSE'])\n",
    "# print(f'MMSE MSE: {mse_MMSE}')\n",
    "mse_CDR = mean_squared_error(results['True CDR'], results['Predicted CDR'])\n",
    "# print(f'CDR MSE: {mse_CDR}')\n",
    "mse_SES = mean_squared_error(results['True SES'], results['Predicted SES'])\n",
    "# print(f'SES MSE: {mse_SES}')\n",
    "\n",
    "r2_MMSE = r2_score(results['True MMSE'], results['Predicted MMSE'])\n",
    "# print(f'MMSE R2: {r2_MMSE}')\n",
    "r2_CDR = r2_score(results['True CDR'], results['Predicted CDR'])\n",
    "# print(f'CDR R2: {r2_CDR}')\n",
    "r2_SES = r2_score(results['True SES'], results['Predicted SES'])\n",
    "# print(f'SES R2: {r2_SES}')\n",
    "\n",
    "rmse_MMSE = root_mean_squared_error(results['True MMSE'], results['Predicted MMSE'])\n",
    "# print(f'MMSE RMSE: {rmse_MMSE}')\n",
    "rmse_CDR = root_mean_squared_error(results['True CDR'], results['Predicted CDR'])\n",
    "# print(f'CDR RMSE: {rmse_CDR}')\n",
    "rmse_SES = root_mean_squared_error(results['True SES'], results['Predicted SES'])\n",
    "# print(f'SES RMSE: {rmse_SES}')\n",
    "\n",
    "new_data = pd.DataFrame([{'Type': 'Regression', 'model': 'MR1_2', 'MMSE MAE': mae_MMSE, 'CDR MAE': mae_CDR, 'SES MAE': mae_SES, 'MMSE MSE': mse_MMSE, 'CDR MSE': mse_CDR, 'SES MSE': mse_SES, 'MMSE R2': r2_MMSE, 'CDR R2': r2_CDR, 'SES R2': r2_SES, 'MMSE RMSE': rmse_MMSE, 'CDR RMSE': rmse_CDR, 'SES RMSE': rmse_SES}])\n",
    "\n",
    "regression_dataframe = pd.concat([regression_dataframe, new_data], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regression MR1_2 test\n",
    "\n",
    "running_loss = 0.0\n",
    "results = []\n",
    "for folder in os.listdir('./test'):\n",
    "    if os.path.isdir('./test' + '/'+folder):\n",
    "        folder_path = './test'+'/'+folder\n",
    "        files = [f for f in os.listdir(folder_path) if f.endswith('.npy') and mode in f and f[0:4] in patients_codes_set]\n",
    "        if folder == 'NonDemented':\n",
    "            label = 0\n",
    "        elif folder == 'VeryMildDemented':\n",
    "            label = 1\n",
    "        elif folder == 'MildDemented':\n",
    "            label = 2\n",
    "        elif folder == 'ModerateDemented':\n",
    "            label = 3\n",
    "        for f in files :\n",
    "            data = np.load(os.path.join(folder_path, f))\n",
    "            code = f[0:4]\n",
    "            x = data_frame[data_frame['ID'].str.contains(code)][['Age', 'Educ', 'eTIV', 'nWBV', 'ASF']].to_numpy()\n",
    "            x = torch.tensor(x).float()\n",
    "            y = data_frame[data_frame['ID'].str.contains(code)][['MMSE', 'CDR', 'SES']].to_numpy()\n",
    "            model.eval()\n",
    "            input_tensor = torch.clamp(torch.tensor(data), 0, 1)\n",
    "            outputs = model(input_tensor, x)\n",
    "            loss = criterion(outputs, torch.tensor(y).float())\n",
    "            running_loss += loss.item()\n",
    "            results.append((outputs.detach().numpy(), y))\n",
    "results = np.array(results).reshape(-1, 6)\n",
    "results = pd.DataFrame(results, columns=['Predicted MMSE', 'Predicted CDR', 'Predicted SES', 'True MMSE', 'True CDR', 'True SES'])\n",
    "\n",
    "results.to_csv('test_results/'+mode+'_'+'results_reg.csv', index=False)\n",
    "\n",
    "# adding MR1_2 results to the dataframe\n",
    "\n",
    "mae_MMSE = mean_absolute_error(results['True MMSE'], results['Predicted MMSE'])\n",
    "# print(f'MMSE MAE: {mae_MMSE}')\n",
    "mae_CDR = mean_absolute_error(results['True CDR'], results['Predicted CDR'])\n",
    "# print(f'CDR MAE: {mae_CDR}')\n",
    "mae_SES = mean_absolute_error(results['True SES'], results['Predicted SES'])\n",
    "# print(f'SES MAE: {mae_SES}')\n",
    "\n",
    "mse_MMSE = mean_squared_error(results['True MMSE'], results['Predicted MMSE'])\n",
    "# print(f'MMSE MSE: {mse_MMSE}')\n",
    "mse_CDR = mean_squared_error(results['True CDR'], results['Predicted CDR'])\n",
    "# print(f'CDR MSE: {mse_CDR}')\n",
    "mse_SES = mean_squared_error(results['True SES'], results['Predicted SES'])\n",
    "# print(f'SES MSE: {mse_SES}')\n",
    "\n",
    "r2_MMSE = r2_score(results['True MMSE'], results['Predicted MMSE'])\n",
    "# print(f'MMSE R2: {r2_MMSE}')\n",
    "r2_CDR = r2_score(results['True CDR'], results['Predicted CDR'])\n",
    "# print(f'CDR R2: {r2_CDR}')\n",
    "r2_SES = r2_score(results['True SES'], results['Predicted SES'])\n",
    "# print(f'SES R2: {r2_SES}')\n",
    "\n",
    "rmse_MMSE = root_mean_squared_error(results['True MMSE'], results['Predicted MMSE'])\n",
    "# print(f'MMSE RMSE: {rmse_MMSE}')\n",
    "rmse_CDR = root_mean_squared_error(results['True CDR'], results['Predicted CDR'])\n",
    "# print(f'CDR RMSE: {rmse_CDR}')\n",
    "rmse_SES = root_mean_squared_error(results['True SES'], results['Predicted SES'])\n",
    "# print(f'SES RMSE: {rmse_SES}')\n",
    "\n",
    "new_data = pd.DataFrame([{'Type': 'Regression', 'model': 'MR1_2', 'MMSE MAE': mae_MMSE, 'CDR MAE': mae_CDR, 'SES MAE': mae_SES, 'MMSE MSE': mse_MMSE, 'CDR MSE': mse_CDR, 'SES MSE': mse_SES, 'MMSE R2': r2_MMSE, 'CDR R2': r2_CDR, 'SES R2': r2_SES, 'MMSE RMSE': rmse_MMSE, 'CDR RMSE': rmse_CDR, 'SES RMSE': rmse_SES}])\n",
    "\n",
    "test_regression_dataframe = pd.concat([test_regression_dataframe, new_data], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regression MR1_3\n",
    "model = CombinedModel(vit_model).to(device)\n",
    "model_load_path = 'models/MR1_1_reg.pth'\n",
    "model.load_state_dict(torch.load(model_load_path))\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.use_deterministic_algorithms(True)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "mode_list = ['MR1_1', 'MR1_2', 'MR1_3', 'MR1_4']\n",
    "mode = 'MR1_3'\n",
    "\n",
    "for epoch in range(501):\n",
    "    running_loss = 0.0\n",
    "    results = []\n",
    "    for folder in os.listdir('./combined_data'):\n",
    "        if os.path.isdir('./combined_data' + '/'+folder):\n",
    "            folder_path = './combined_data'+'/'+folder\n",
    "            files = [f for f in os.listdir(folder_path) if f.endswith('.npy') and mode in f and f[0:4] in patients_codes_set]\n",
    "            if folder == 'NonDemented':\n",
    "                label = 0\n",
    "            elif folder == 'VeryMildDemented':\n",
    "                label = 1\n",
    "            elif folder == 'MildDemented':\n",
    "                label = 2\n",
    "            elif folder == 'ModerateDemented':\n",
    "                label = 3\n",
    "            for f in files :\n",
    "                data = np.load(os.path.join(folder_path, f))\n",
    "                code = f[0:4]\n",
    "                x = data_frame[data_frame['ID'].str.contains(code)][['Age', 'Educ', 'eTIV', 'nWBV', 'ASF']].to_numpy()\n",
    "                x = torch.tensor(x).float()\n",
    "                y = data_frame[data_frame['ID'].str.contains(code)][['MMSE', 'CDR', 'SES']].to_numpy()\n",
    "                model.train()\n",
    "                optimizer.zero_grad()\n",
    "                input_tensor = torch.clamp(torch.tensor(data), 0, 1)\n",
    "                outputs = model(input_tensor, x)\n",
    "                loss = criterion(outputs, torch.tensor(y).float())\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                running_loss += loss.item()\n",
    "                results.append((outputs.detach().numpy(), y))\n",
    "    if epoch == 500:\n",
    "        print(f'Epoch {epoch} loss: {running_loss}')\n",
    "\n",
    "# convert the results to a numpy array\n",
    "results = np.array(results).reshape(-1, 6)\n",
    "results = pd.DataFrame(results, columns=['Predicted MMSE', 'Predicted CDR', 'Predicted SES', 'True MMSE', 'True CDR', 'True SES'])\n",
    "results.to_csv('results/'+mode+'_'+'results_reg.csv', index=False)\n",
    "\n",
    "model_save_path = 'models/'+mode+'_'+'reg.pth'\n",
    "torch.save(model.state_dict(), model_save_path)\n",
    "print(f\"Model saved to {model_save_path}\")\n",
    "\n",
    "model_test = CombinedModel(vit_model)\n",
    "\n",
    "# Load the model state\n",
    "# model_load_path = model_save_path\n",
    "# model.load_state_dict(torch.load(model_load_path))\n",
    "# model.eval() # Set the model to evaluation mode\n",
    "# print(f\"Model loaded from {model_load_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding MR1_3 results to the dataframe\n",
    "\n",
    "mae_MMSE = mean_absolute_error(results['True MMSE'], results['Predicted MMSE'])\n",
    "# print(f'MMSE MAE: {mae_MMSE}')\n",
    "mae_CDR = mean_absolute_error(results['True CDR'], results['Predicted CDR'])\n",
    "# print(f'CDR MAE: {mae_CDR}')\n",
    "mae_SES = mean_absolute_error(results['True SES'], results['Predicted SES'])\n",
    "# print(f'SES MAE: {mae_SES}')\n",
    "\n",
    "mse_MMSE = mean_squared_error(results['True MMSE'], results['Predicted MMSE'])\n",
    "# print(f'MMSE MSE: {mse_MMSE}')\n",
    "mse_CDR = mean_squared_error(results['True CDR'], results['Predicted CDR'])\n",
    "# print(f'CDR MSE: {mse_CDR}')\n",
    "mse_SES = mean_squared_error(results['True SES'], results['Predicted SES'])\n",
    "# print(f'SES MSE: {mse_SES}')\n",
    "\n",
    "r2_MMSE = r2_score(results['True MMSE'], results['Predicted MMSE'])\n",
    "# print(f'MMSE R2: {r2_MMSE}')\n",
    "r2_CDR = r2_score(results['True CDR'], results['Predicted CDR'])\n",
    "# print(f'CDR R2: {r2_CDR}')\n",
    "r2_SES = r2_score(results['True SES'], results['Predicted SES'])\n",
    "# print(f'SES R2: {r2_SES}')\n",
    "\n",
    "rmse_MMSE = root_mean_squared_error(results['True MMSE'], results['Predicted MMSE'])\n",
    "# print(f'MMSE RMSE: {rmse_MMSE}')\n",
    "rmse_CDR = root_mean_squared_error(results['True CDR'], results['Predicted CDR'])\n",
    "# print(f'CDR RMSE: {rmse_CDR}')\n",
    "rmse_SES = root_mean_squared_error(results['True SES'], results['Predicted SES'])\n",
    "# print(f'SES RMSE: {rmse_SES}')\n",
    "\n",
    "new_data = pd.DataFrame([{'Type': 'Regression', 'model': 'MR1_3', 'MMSE MAE': mae_MMSE, 'CDR MAE': mae_CDR, 'SES MAE': mae_SES, 'MMSE MSE': mse_MMSE, 'CDR MSE': mse_CDR, 'SES MSE': mse_SES, 'MMSE R2': r2_MMSE, 'CDR R2': r2_CDR, 'SES R2': r2_SES, 'MMSE RMSE': rmse_MMSE, 'CDR RMSE': rmse_CDR, 'SES RMSE': rmse_SES}])\n",
    "\n",
    "regression_dataframe = pd.concat([regression_dataframe, new_data], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regression MR1_3 test\n",
    "\n",
    "running_loss = 0.0\n",
    "results = []\n",
    "for folder in os.listdir('./test'):\n",
    "    if os.path.isdir('./test' + '/'+folder):\n",
    "        folder_path = './test'+'/'+folder\n",
    "        files = [f for f in os.listdir(folder_path) if f.endswith('.npy') and mode in f and f[0:4] in patients_codes_set]\n",
    "        if folder == 'NonDemented':\n",
    "            label = 0\n",
    "        elif folder == 'VeryMildDemented':\n",
    "            label = 1\n",
    "        elif folder == 'MildDemented':\n",
    "            label = 2\n",
    "        elif folder == 'ModerateDemented':\n",
    "            label = 3\n",
    "        for f in files :\n",
    "            data = np.load(os.path.join(folder_path, f))\n",
    "            code = f[0:4]\n",
    "            x = data_frame[data_frame['ID'].str.contains(code)][['Age', 'Educ', 'eTIV', 'nWBV', 'ASF']].to_numpy()\n",
    "            x = torch.tensor(x).float()\n",
    "            y = data_frame[data_frame['ID'].str.contains(code)][['MMSE', 'CDR', 'SES']].to_numpy()\n",
    "            model.eval()\n",
    "            input_tensor = torch.clamp(torch.tensor(data), 0, 1)\n",
    "            outputs = model(input_tensor, x)\n",
    "            loss = criterion(outputs, torch.tensor(y).float())\n",
    "            running_loss += loss.item()\n",
    "            results.append((outputs.detach().numpy(), y))\n",
    "results = np.array(results).reshape(-1, 6)\n",
    "results = pd.DataFrame(results, columns=['Predicted MMSE', 'Predicted CDR', 'Predicted SES', 'True MMSE', 'True CDR', 'True SES'])\n",
    "\n",
    "results.to_csv('test_results/'+mode+'_'+'results_reg.csv', index=False)\n",
    "\n",
    "# adding MR1_2 results to the dataframe\n",
    "\n",
    "mae_MMSE = mean_absolute_error(results['True MMSE'], results['Predicted MMSE'])\n",
    "# print(f'MMSE MAE: {mae_MMSE}')\n",
    "mae_CDR = mean_absolute_error(results['True CDR'], results['Predicted CDR'])\n",
    "# print(f'CDR MAE: {mae_CDR}')\n",
    "mae_SES = mean_absolute_error(results['True SES'], results['Predicted SES'])\n",
    "# print(f'SES MAE: {mae_SES}')\n",
    "\n",
    "mse_MMSE = mean_squared_error(results['True MMSE'], results['Predicted MMSE'])\n",
    "# print(f'MMSE MSE: {mse_MMSE}')\n",
    "mse_CDR = mean_squared_error(results['True CDR'], results['Predicted CDR'])\n",
    "# print(f'CDR MSE: {mse_CDR}')\n",
    "mse_SES = mean_squared_error(results['True SES'], results['Predicted SES'])\n",
    "# print(f'SES MSE: {mse_SES}')\n",
    "\n",
    "r2_MMSE = r2_score(results['True MMSE'], results['Predicted MMSE'])\n",
    "# print(f'MMSE R2: {r2_MMSE}')\n",
    "r2_CDR = r2_score(results['True CDR'], results['Predicted CDR'])\n",
    "# print(f'CDR R2: {r2_CDR}')\n",
    "r2_SES = r2_score(results['True SES'], results['Predicted SES'])\n",
    "# print(f'SES R2: {r2_SES}')\n",
    "\n",
    "rmse_MMSE = root_mean_squared_error(results['True MMSE'], results['Predicted MMSE'])\n",
    "# print(f'MMSE RMSE: {rmse_MMSE}')\n",
    "rmse_CDR = root_mean_squared_error(results['True CDR'], results['Predicted CDR'])\n",
    "# print(f'CDR RMSE: {rmse_CDR}')\n",
    "rmse_SES = root_mean_squared_error(results['True SES'], results['Predicted SES'])\n",
    "# print(f'SES RMSE: {rmse_SES}')\n",
    "\n",
    "new_data = pd.DataFrame([{'Type': 'Regression', 'model': 'MR1_3', 'MMSE MAE': mae_MMSE, 'CDR MAE': mae_CDR, 'SES MAE': mae_SES, 'MMSE MSE': mse_MMSE, 'CDR MSE': mse_CDR, 'SES MSE': mse_SES, 'MMSE R2': r2_MMSE, 'CDR R2': r2_CDR, 'SES R2': r2_SES, 'MMSE RMSE': rmse_MMSE, 'CDR RMSE': rmse_CDR, 'SES RMSE': rmse_SES}])\n",
    "\n",
    "test_regression_dataframe = pd.concat([test_regression_dataframe, new_data], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regression MR1_4\n",
    "model = CombinedModel(vit_model).to(device)\n",
    "model_load_path = 'models/MR1_1_reg.pth'\n",
    "model.load_state_dict(torch.load(model_load_path))\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.use_deterministic_algorithms(True)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "mode_list = ['MR1_1', 'MR1_2', 'MR1_3', 'MR1_4']\n",
    "mode = 'MR1_4'\n",
    "\n",
    "for epoch in range(501):\n",
    "    running_loss = 0.0\n",
    "    results = []\n",
    "    for folder in os.listdir('./combined_data'):\n",
    "        if os.path.isdir('./combined_data' + '/'+folder):\n",
    "            folder_path = './combined_data'+'/'+folder\n",
    "            files = [f for f in os.listdir(folder_path) if f.endswith('.npy') and mode in f and f[0:4] in patients_codes_set]\n",
    "            if folder == 'NonDemented':\n",
    "                label = 0\n",
    "            elif folder == 'VeryMildDemented':\n",
    "                label = 1\n",
    "            elif folder == 'MildDemented':\n",
    "                label = 2\n",
    "            elif folder == 'ModerateDemented':\n",
    "                label = 3\n",
    "            for f in files :\n",
    "                data = np.load(os.path.join(folder_path, f))\n",
    "                code = f[0:4]\n",
    "                x = data_frame[data_frame['ID'].str.contains(code)][['Age', 'Educ', 'eTIV', 'nWBV', 'ASF']].to_numpy()\n",
    "                x = torch.tensor(x).float()\n",
    "                y = data_frame[data_frame['ID'].str.contains(code)][['MMSE', 'CDR', 'SES']].to_numpy()\n",
    "                model.train()\n",
    "                optimizer.zero_grad()\n",
    "                input_tensor = torch.clamp(torch.tensor(data), 0, 1)\n",
    "                outputs = model(input_tensor, x)\n",
    "                loss = criterion(outputs, torch.tensor(y).float())\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                running_loss += loss.item()\n",
    "                results.append((outputs.detach().numpy(), y))\n",
    "    if epoch == 500:\n",
    "        print(f'Epoch {epoch} loss: {running_loss}')\n",
    "\n",
    "# convert the results to a numpy array\n",
    "results = np.array(results).reshape(-1, 6)\n",
    "results = pd.DataFrame(results, columns=['Predicted MMSE', 'Predicted CDR', 'Predicted SES', 'True MMSE', 'True CDR', 'True SES'])\n",
    "results.to_csv('results/'+mode+'_'+'results_reg.csv', index=False)\n",
    "\n",
    "model_save_path = 'models/'+mode+'_'+'reg.pth'\n",
    "torch.save(model.state_dict(), model_save_path)\n",
    "print(f\"Model saved to {model_save_path}\")\n",
    "\n",
    "model_test = CombinedModel(vit_model)\n",
    "\n",
    "# Load the model state\n",
    "# model_load_path = model_save_path\n",
    "# model.load_state_dict(torch.load(model_load_path))\n",
    "# model.eval()  # Set the model to evaluation mode\n",
    "# print(f\"Model loaded from {model_load_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding MR1_4 results to the dataframe\n",
    "\n",
    "mae_MMSE = mean_absolute_error(results['True MMSE'], results['Predicted MMSE'])\n",
    "# print(f'MMSE MAE: {mae_MMSE}')\n",
    "mae_CDR = mean_absolute_error(results['True CDR'], results['Predicted CDR'])\n",
    "# print(f'CDR MAE: {mae_CDR}')\n",
    "mae_SES = mean_absolute_error(results['True SES'], results['Predicted SES'])\n",
    "# print(f'SES MAE: {mae_SES}')\n",
    "\n",
    "mse_MMSE = mean_squared_error(results['True MMSE'], results['Predicted MMSE'])\n",
    "# print(f'MMSE MSE: {mse_MMSE}')\n",
    "mse_CDR = mean_squared_error(results['True CDR'], results['Predicted CDR'])\n",
    "# print(f'CDR MSE: {mse_CDR}')\n",
    "mse_SES = mean_squared_error(results['True SES'], results['Predicted SES'])\n",
    "# print(f'SES MSE: {mse_SES}')\n",
    "\n",
    "r2_MMSE = r2_score(results['True MMSE'], results['Predicted MMSE'])\n",
    "# print(f'MMSE R2: {r2_MMSE}')\n",
    "r2_CDR = r2_score(results['True CDR'], results['Predicted CDR'])\n",
    "# print(f'CDR R2: {r2_CDR}')\n",
    "r2_SES = r2_score(results['True SES'], results['Predicted SES'])\n",
    "# print(f'SES R2: {r2_SES}')\n",
    "\n",
    "rmse_MMSE = root_mean_squared_error(results['True MMSE'], results['Predicted MMSE'])\n",
    "# print(f'MMSE RMSE: {rmse_MMSE}')\n",
    "rmse_CDR = root_mean_squared_error(results['True CDR'], results['Predicted CDR'])\n",
    "# print(f'CDR RMSE: {rmse_CDR}')\n",
    "rmse_SES = root_mean_squared_error(results['True SES'], results['Predicted SES'])\n",
    "# print(f'SES RMSE: {rmse_SES}')\n",
    "\n",
    "new_data = pd.DataFrame([{'Type': 'Regression', 'model': 'MR1_4', 'MMSE MAE': mae_MMSE, 'CDR MAE': mae_CDR, 'SES MAE': mae_SES, 'MMSE MSE': mse_MMSE, 'CDR MSE': mse_CDR, 'SES MSE': mse_SES, 'MMSE R2': r2_MMSE, 'CDR R2': r2_CDR, 'SES R2': r2_SES, 'MMSE RMSE': rmse_MMSE, 'CDR RMSE': rmse_CDR, 'SES RMSE': rmse_SES}])\n",
    "\n",
    "regression_dataframe = pd.concat([regression_dataframe, new_data], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regression MR1_4 test\n",
    "\n",
    "running_loss = 0.0\n",
    "results = []\n",
    "for folder in os.listdir('./test'):\n",
    "    if os.path.isdir('./test' + '/'+folder):\n",
    "        folder_path = './test'+'/'+folder\n",
    "        files = [f for f in os.listdir(folder_path) if f.endswith('.npy') and mode in f and f[0:4] in patients_codes_set]\n",
    "        if folder == 'NonDemented':\n",
    "            label = 0\n",
    "        elif folder == 'VeryMildDemented':\n",
    "            label = 1\n",
    "        elif folder == 'MildDemented':\n",
    "            label = 2\n",
    "        elif folder == 'ModerateDemented':\n",
    "            label = 3\n",
    "        for f in files :\n",
    "            data = np.load(os.path.join(folder_path, f))\n",
    "            code = f[0:4]\n",
    "            x = data_frame[data_frame['ID'].str.contains(code)][['Age', 'Educ', 'eTIV', 'nWBV', 'ASF']].to_numpy()\n",
    "            x = torch.tensor(x).float()\n",
    "            y = data_frame[data_frame['ID'].str.contains(code)][['MMSE', 'CDR', 'SES']].to_numpy()\n",
    "            model.eval()\n",
    "            input_tensor = torch.clamp(torch.tensor(data), 0, 1)\n",
    "            outputs = model(input_tensor, x)\n",
    "            loss = criterion(outputs, torch.tensor(y).float())\n",
    "            running_loss += loss.item()\n",
    "            results.append((outputs.detach().numpy(), y))\n",
    "results = np.array(results).reshape(-1, 6)\n",
    "results = pd.DataFrame(results, columns=['Predicted MMSE', 'Predicted CDR', 'Predicted SES', 'True MMSE', 'True CDR', 'True SES'])\n",
    "\n",
    "results.to_csv('test_results/'+mode+'_'+'results_reg.csv', index=False)\n",
    "\n",
    "# adding MR1_2 results to the dataframe\n",
    "\n",
    "mae_MMSE = mean_absolute_error(results['True MMSE'], results['Predicted MMSE'])\n",
    "# print(f'MMSE MAE: {mae_MMSE}')\n",
    "mae_CDR = mean_absolute_error(results['True CDR'], results['Predicted CDR'])\n",
    "# print(f'CDR MAE: {mae_CDR}')\n",
    "mae_SES = mean_absolute_error(results['True SES'], results['Predicted SES'])\n",
    "# print(f'SES MAE: {mae_SES}')\n",
    "\n",
    "mse_MMSE = mean_squared_error(results['True MMSE'], results['Predicted MMSE'])\n",
    "# print(f'MMSE MSE: {mse_MMSE}')\n",
    "mse_CDR = mean_squared_error(results['True CDR'], results['Predicted CDR'])\n",
    "# print(f'CDR MSE: {mse_CDR}')\n",
    "mse_SES = mean_squared_error(results['True SES'], results['Predicted SES'])\n",
    "# print(f'SES MSE: {mse_SES}')\n",
    "\n",
    "r2_MMSE = r2_score(results['True MMSE'], results['Predicted MMSE'])\n",
    "# print(f'MMSE R2: {r2_MMSE}')\n",
    "r2_CDR = r2_score(results['True CDR'], results['Predicted CDR'])\n",
    "# print(f'CDR R2: {r2_CDR}')\n",
    "r2_SES = r2_score(results['True SES'], results['Predicted SES'])\n",
    "# print(f'SES R2: {r2_SES}')\n",
    "\n",
    "rmse_MMSE = root_mean_squared_error(results['True MMSE'], results['Predicted MMSE'])\n",
    "# print(f'MMSE RMSE: {rmse_MMSE}')\n",
    "rmse_CDR = root_mean_squared_error(results['True CDR'], results['Predicted CDR'])\n",
    "# print(f'CDR RMSE: {rmse_CDR}')\n",
    "rmse_SES = root_mean_squared_error(results['True SES'], results['Predicted SES'])\n",
    "# print(f'SES RMSE: {rmse_SES}')\n",
    "\n",
    "new_data = pd.DataFrame([{'Type': 'Regression', 'model': 'MR1_4', 'MMSE MAE': mae_MMSE, 'CDR MAE': mae_CDR, 'SES MAE': mae_SES, 'MMSE MSE': mse_MMSE, 'CDR MSE': mse_CDR, 'SES MSE': mse_SES, 'MMSE R2': r2_MMSE, 'CDR R2': r2_CDR, 'SES R2': r2_SES, 'MMSE RMSE': rmse_MMSE, 'CDR RMSE': rmse_CDR, 'SES RMSE': rmse_SES}])\n",
    "\n",
    "test_regression_dataframe = pd.concat([test_regression_dataframe, new_data], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification model\n",
    "# Initialize the feature extractor and the model\n",
    "feature_extractor = ViTImageProcessor.from_pretrained('google/vit-base-patch16-224-in21k')\n",
    "vit_model = ViTModel.from_pretrained('google/vit-base-patch16-224-in21k')\n",
    "\n",
    "# Freeze the ViT model parameters\n",
    "for param in vit_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "class CombinedModel_classfication(nn.Module):\n",
    "    def __init__(self, vit_model):\n",
    "        super(CombinedModel_classfication, self).__init__()\n",
    "        self.vit_model = vit_model\n",
    "        self.linear_layer = nn.Linear(vit_model.config.hidden_size, 3)\n",
    "        self.linear_layer.weight.data.normal_(mean=0.0, std=0.02)\n",
    "        self.out = nn.Linear(3, 4)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.out.weight.data.normal_(mean=0.0, std=0.02)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Preprocess the input tensor\n",
    "        x = x.mean(dim=0, keepdim=True).repeat(3, 1, 1)\n",
    "        inputs = feature_extractor(images=x, return_tensors=\"pt\")\n",
    "        outputs = self.vit_model(**inputs)\n",
    "        last_hidden_state = outputs.last_hidden_state\n",
    "        pooled_output = last_hidden_state.mean(dim=1)\n",
    "        final_output = self.linear_layer(pooled_output)\n",
    "        final_output = self.relu(final_output)\n",
    "        final_output = self.out(final_output)\n",
    "        final_output = self.softmax(final_output)\n",
    "        return final_output\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Device:', device)\n",
    "model = CombinedModel_classfication(vit_model).to(device)\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_dataframe = pd.DataFrame(columns=['Type', 'model', 'Accuracy', 'Precision', 'Recall', 'True positive', 'Sensitivity', 'Specificity', 'F1 Score'])\n",
    "\n",
    "test_classification_dataframe = pd.DataFrame(columns=['Type', 'model', 'Accuracy', 'Precision', 'Recall', 'True positive', 'Sensitivity', 'Specificity', 'F1 Score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification MR1_1\n",
    "model = CombinedModel_classfication(vit_model).to(device)\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.use_deterministic_algorithms(True)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "mode_list = ['MR1_1', 'MR1_2', 'MR1_3', 'MR1_4']\n",
    "mode = 'MR1_1'\n",
    "\n",
    "for epoch in range(10001):\n",
    "    running_loss = 0.0\n",
    "    results = []\n",
    "    for folder in os.listdir('./combined_data'):\n",
    "        if os.path.isdir('./combined_data' + '/'+folder):\n",
    "            folder_path = './combined_data'+'/'+folder\n",
    "            files = [f for f in os.listdir(folder_path) if f.endswith('.npy') and mode in f and f[0:4] in patients_codes_set]\n",
    "            if folder == 'NonDemented':\n",
    "                label = 0\n",
    "            elif folder == 'VeryMildDemented':\n",
    "                label = 1\n",
    "            elif folder == 'MildDemented':\n",
    "                label = 2\n",
    "            elif folder == 'ModerateDemented':\n",
    "                label = 3\n",
    "            for f in files :\n",
    "                data = np.load(os.path.join(folder_path, f))\n",
    "                code = f[0:4]\n",
    "                y = data_frame[data_frame['ID'].str.contains(code)][['MMSE', 'CDR', 'SES']].to_numpy()\n",
    "                model.train()\n",
    "                optimizer.zero_grad()\n",
    "                input_tensor = torch.clamp(torch.tensor(data), 0, 1)\n",
    "                outputs = model(input_tensor)\n",
    "                target = torch.tensor([label]).to(device)\n",
    "                loss = criterion(outputs, target)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                running_loss += loss.item()\n",
    "                results.append((np.argmax(outputs.detach().numpy()), label))\n",
    "    if epoch == 500:\n",
    "        print(f'Epoch {epoch} loss: {running_loss}')\n",
    "\n",
    "# convert the results to a numpy array\n",
    "results = np.array(results).reshape(-1, 2)\n",
    "results = pd.DataFrame(results, columns=['Predicted class', 'True class'])\n",
    "results.to_csv('results/'+mode+'_'+'results_class.csv', index=False)\n",
    "\n",
    "model_save_path = 'models/'+mode+'_'+'class.pth'\n",
    "torch.save(model.state_dict(), model_save_path)\n",
    "print(f\"Model saved to {model_save_path}\")\n",
    "\n",
    "model_test = CombinedModel(vit_model)\n",
    "\n",
    "# Load the model state\n",
    "# model_load_path = model_save_path\n",
    "# model.load_state_dict(torch.load(model_load_path))\n",
    "# model.eval()  # Set the model to evaluation mode\n",
    "# print(f\"Model loaded from {model_load_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding MR1_1 results to the dataframe\n",
    "\n",
    "accuracy = (results['Predicted class'] == results['True class']).sum() / len(results)\n",
    "# print(f'Accuracy: {accuracy}')\n",
    "\n",
    "pre_0 = ((results['Predicted class'] == 0) & (results['True class'] == 0)).sum() / ((results['True class'] == 0).sum())\n",
    "pre_1 = ((results['Predicted class'] == 1) & (results['True class'] == 1)).sum() / ((results['True class'] == 1).sum())\n",
    "pre_2 = ((results['Predicted class'] == 2) & (results['True class'] == 2)).sum() / ((results['True class'] == 2).sum())\n",
    "pre_3 = +((results['Predicted class'] == 3) & (results['True class'] == 3)).sum() / ((results['True class'] == 3).sum())\n",
    "pre_list = [pre_0, pre_1, pre_2, pre_3]\n",
    "pre_list = [ele for ele in pre_list if not math.isnan(ele)]\n",
    "precision = sum(pre_list) / len(pre_list)\n",
    "# print(f'Precision: {precision}')\n",
    "\n",
    "recall_0 = (results['Predicted class'] == 0).sum() / ((results['True class'] == 0).sum())\n",
    "recall_1 = (results['Predicted class'] == 1).sum() / ((results['True class'] == 1).sum())\n",
    "recall_2 = (results['Predicted class'] == 2).sum() / ((results['True class'] == 2).sum())\n",
    "recall_3 = (results['Predicted class'] == 3).sum() / ((results['True class'] == 3).sum())\n",
    "recall_list = [recall_0, recall_1, recall_2, recall_3]\n",
    "recall_list = [ele for ele in recall_list if not math.isnan(ele)]\n",
    "recall = sum(recall_list) / len(recall_list)\n",
    "# print(f'Recall: {recall}')\n",
    "\n",
    "true_positive = (results['Predicted class'] == results['True class']).sum()\n",
    "# print(f'True positive: {true_positive}')\n",
    "\n",
    "sen_0 = ((results['Predicted class'] == 0) & (results['True class'] == 0)).sum() / ((results['True class'] == 0).sum())\n",
    "sen_1 = ((results['Predicted class'] == 1) & (results['True class'] == 1)).sum() / ((results['True class'] == 1).sum())\n",
    "sen_2 = ((results['Predicted class'] == 2) & (results['True class'] == 2)).sum() / ((results['True class'] == 2).sum())\n",
    "sen_3 = ((results['Predicted class'] == 3) & (results['True class'] == 3)).sum() / ((results['True class'] == 3).sum())\n",
    "sen_list = [sen_0, sen_1, sen_2, sen_3]\n",
    "sen_list = [ele for ele in sen_list if not math.isnan(ele)]\n",
    "sensitivity = sum(sen_list) / len(sen_list)\n",
    "# print(f'Sensitivity: {sensitivity}')\n",
    "\n",
    "spec_0 = ((results['Predicted class'] != 0) & (results['True class'] != 0)).sum() / (((results['Predicted class'] != 0) & (results['True class'] != 0)).sum()+((results['Predicted class'] == 0) & (results['True class'] != 0)).sum())\n",
    "spec_1 = ((results['Predicted class'] != 1) & (results['True class'] != 1)).sum() / (((results['Predicted class'] != 1) & (results['True class'] != 1)).sum()+((results['Predicted class'] == 1) & (results['True class'] != 1)).sum())\n",
    "spec_2 = ((results['Predicted class'] != 2) & (results['True class'] != 2)).sum() / (((results['Predicted class'] != 2) & (results['True class'] != 2)).sum()+((results['Predicted class'] == 2) & (results['True class'] != 2)).sum())\n",
    "spec_3 = ((results['Predicted class'] != 3) & (results['True class'] != 3)).sum() / (((results['Predicted class'] != 3) & (results['True class'] != 3)).sum()+ ((results['Predicted class'] == 3) & (results['True class'] != 3)).sum())\n",
    "specificity_list = [spec_0, spec_1, spec_2, spec_3]\n",
    "specificity_list = [ele for ele in specificity_list if not math.isnan(ele)]\n",
    "specificity = sum(specificity_list) / len(specificity_list)\n",
    "# print(f'Specificity: {specificity}')\n",
    "\n",
    "f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "# print(f'F1 Score: {f1_score}')\n",
    "\n",
    "new_data = pd.DataFrame([{'Type': 'Classification', 'model': 'MR1_1', 'Accuracy': accuracy, 'Precision': precision, 'Recall': recall, 'True positive': true_positive, 'Sensitivity': sensitivity, 'Specificity': specificity, 'F1 Score': f1_score}])\n",
    "\n",
    "classification_dataframe = pd.concat([classification_dataframe, new_data], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification MR1_1 test\n",
    "\n",
    "running_loss = 0.0\n",
    "results = []\n",
    "for folder in os.listdir('./test'):\n",
    "    if os.path.isdir('./test' + '/'+folder):\n",
    "        folder_path = './test'+'/'+folder\n",
    "        files = [f for f in os.listdir(folder_path) if f.endswith('.npy') and mode in f and f[0:4] in patients_codes_set]\n",
    "        if folder == 'NonDemented':\n",
    "            label = 0\n",
    "        elif folder == 'VeryMildDemented':\n",
    "            label = 1\n",
    "        elif folder == 'MildDemented':\n",
    "            label = 2\n",
    "        elif folder == 'ModerateDemented':\n",
    "            label = 3\n",
    "        for f in files :\n",
    "            data = np.load(os.path.join(folder_path, f))\n",
    "            code = f[0:4]\n",
    "            y = data_frame[data_frame['ID'].str.contains(code)][['MMSE', 'CDR', 'SES']].to_numpy()\n",
    "            model.eval()\n",
    "            input_tensor = torch.clamp(torch.tensor(data), 0, 1)\n",
    "            outputs = model(input_tensor)\n",
    "            target = torch.tensor([label]).to(device)\n",
    "            loss = criterion(outputs, target)\n",
    "            running_loss += loss.item()\n",
    "            results.append((np.argmax(outputs.detach().numpy()), label))\n",
    "\n",
    "\n",
    "# convert the results to a numpy array\n",
    "results = np.array(results).reshape(-1, 2)\n",
    "results = pd.DataFrame(results, columns=['Predicted class', 'True class'])\n",
    "results.to_csv('test_results/'+mode+'_'+'results_class.csv', index=False)\n",
    "\n",
    "accuracy = (results['Predicted class'] == results['True class']).sum() / len(results)\n",
    "# print(f'Accuracy: {accuracy}')\n",
    "\n",
    "pre_0 = ((results['Predicted class'] == 0) & (results['True class'] == 0)).sum() / ((results['True class'] == 0).sum())\n",
    "pre_1 = ((results['Predicted class'] == 1) & (results['True class'] == 1)).sum() / ((results['True class'] == 1).sum())\n",
    "pre_2 = ((results['Predicted class'] == 2) & (results['True class'] == 2)).sum() / ((results['True class'] == 2).sum())\n",
    "pre_3 = +((results['Predicted class'] == 3) & (results['True class'] == 3)).sum() / ((results['True class'] == 3).sum())\n",
    "pre_list = [pre_0, pre_1, pre_2, pre_3]\n",
    "pre_list = [ele for ele in pre_list if not math.isnan(ele)]\n",
    "precision = sum(pre_list) / len(pre_list)\n",
    "# print(f'Precision: {precision}')\n",
    "\n",
    "recall_0 = (results['Predicted class'] == 0).sum() / ((results['True class'] == 0).sum())\n",
    "recall_1 = (results['Predicted class'] == 1).sum() / ((results['True class'] == 1).sum())\n",
    "recall_2 = (results['Predicted class'] == 2).sum() / ((results['True class'] == 2).sum())\n",
    "recall_3 = (results['Predicted class'] == 3).sum() / ((results['True class'] == 3).sum())\n",
    "recall_list = [recall_0, recall_1, recall_2, recall_3]\n",
    "recall_list = [ele for ele in recall_list if not math.isnan(ele)]\n",
    "recall = sum(recall_list) / len(recall_list)\n",
    "# print(f'Recall: {recall}')\n",
    "\n",
    "true_positive = (results['Predicted class'] == results['True class']).sum()\n",
    "# print(f'True positive: {true_positive}')\n",
    "\n",
    "sen_0 = ((results['Predicted class'] == 0) & (results['True class'] == 0)).sum() / ((results['True class'] == 0).sum())\n",
    "sen_1 = ((results['Predicted class'] == 1) & (results['True class'] == 1)).sum() / ((results['True class'] == 1).sum())\n",
    "sen_2 = ((results['Predicted class'] == 2) & (results['True class'] == 2)).sum() / ((results['True class'] == 2).sum())\n",
    "sen_3 = ((results['Predicted class'] == 3) & (results['True class'] == 3)).sum() / ((results['True class'] == 3).sum())\n",
    "sen_list = [sen_0, sen_1, sen_2, sen_3]\n",
    "sen_list = [ele for ele in sen_list if not math.isnan(ele)]\n",
    "sensitivity = sum(sen_list) / len(sen_list)\n",
    "# print(f'Sensitivity: {sensitivity}')\n",
    "\n",
    "spec_0 = ((results['Predicted class'] != 0) & (results['True class'] != 0)).sum() / (((results['Predicted class'] != 0) & (results['True class'] != 0)).sum()+((results['Predicted class'] == 0) & (results['True class'] != 0)).sum())\n",
    "spec_1 = ((results['Predicted class'] != 1) & (results['True class'] != 1)).sum() / (((results['Predicted class'] != 1) & (results['True class'] != 1)).sum()+((results['Predicted class'] == 1) & (results['True class'] != 1)).sum())\n",
    "spec_2 = ((results['Predicted class'] != 2) & (results['True class'] != 2)).sum() / (((results['Predicted class'] != 2) & (results['True class'] != 2)).sum()+((results['Predicted class'] == 2) & (results['True class'] != 2)).sum())\n",
    "spec_3 = ((results['Predicted class'] != 3) & (results['True class'] != 3)).sum() / (((results['Predicted class'] != 3) & (results['True class'] != 3)).sum()+ ((results['Predicted class'] == 3) & (results['True class'] != 3)).sum())\n",
    "specificity_list = [spec_0, spec_1, spec_2, spec_3]\n",
    "specificity_list = [ele for ele in specificity_list if not math.isnan(ele)]\n",
    "specificity = sum(specificity_list) / len(specificity_list)\n",
    "# print(f'Specificity: {specificity}')\n",
    "\n",
    "f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "# print(f'F1 Score: {f1_score}')\n",
    "\n",
    "new_data = pd.DataFrame([{'Type': 'Classification', 'model': 'MR1_1', 'Accuracy': accuracy, 'Precision': precision, 'Recall': recall, 'True positive': true_positive, 'Sensitivity': sensitivity, 'Specificity': specificity, 'F1 Score': f1_score}])\n",
    "\n",
    "test_classification_dataframe = pd.concat([test_classification_dataframe, new_data], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification MR1_2\n",
    "model = CombinedModel_classfication(vit_model).to(device)\n",
    "model_load_path = 'models/MR1_1_class.pth'\n",
    "model.load_state_dict(torch.load(model_load_path))\n",
    "\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.use_deterministic_algorithms(True)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "mode_list = ['MR1_1', 'MR1_2', 'MR1_3', 'MR1_4']\n",
    "mode = 'MR1_2'\n",
    "\n",
    "for epoch in range(501):\n",
    "    running_loss = 0.0\n",
    "    results = []\n",
    "    for folder in os.listdir('./combined_data'):\n",
    "        if os.path.isdir('./combined_data' + '/'+folder):\n",
    "            folder_path = './combined_data'+'/'+folder\n",
    "            files = [f for f in os.listdir(folder_path) if f.endswith('.npy') and mode in f and f[0:4] in patients_codes_set]\n",
    "            if folder == 'NonDemented':\n",
    "                label = 0\n",
    "            elif folder == 'VeryMildDemented':\n",
    "                label = 1\n",
    "            elif folder == 'MildDemented':\n",
    "                label = 2\n",
    "            elif folder == 'ModerateDemented':\n",
    "                label = 3\n",
    "            for f in files :\n",
    "                data = np.load(os.path.join(folder_path, f))\n",
    "                code = f[0:4]\n",
    "                y = data_frame[data_frame['ID'].str.contains(code)][['MMSE', 'CDR', 'SES']].to_numpy()\n",
    "                model.train()\n",
    "                optimizer.zero_grad()\n",
    "                input_tensor = torch.clamp(torch.tensor(data), 0, 1)\n",
    "                outputs = model(input_tensor)\n",
    "                target = torch.tensor([label]).to(device)\n",
    "                loss = criterion(outputs, target)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                running_loss += loss.item()\n",
    "                results.append((np.argmax(outputs.detach().numpy()), label))\n",
    "    if epoch % 100 == 0:\n",
    "        print(f'Epoch {epoch} loss: {running_loss}')\n",
    "\n",
    "# convert the results to a numpy array\n",
    "results = np.array(results).reshape(-1, 2)\n",
    "results = pd.DataFrame(results, columns=['Predicted class', 'True class'])\n",
    "results.to_csv('results/'+mode+'_'+'results_class.csv', index=False)\n",
    "\n",
    "model_save_path = 'models/'+mode+'_'+'class.pth'\n",
    "torch.save(model.state_dict(), model_save_path)\n",
    "print(f\"Model saved to {model_save_path}\")\n",
    "\n",
    "model_test = CombinedModel(vit_model)\n",
    "\n",
    "# Load the model state\n",
    "# model_load_path = model_save_path\n",
    "# model.load_state_dict(torch.load(model_load_path))\n",
    "# model.eval()  # Set the model to evaluation mode\n",
    "# print(f\"Model loaded from {model_load_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding MR1_2 results to the dataframe\n",
    "\n",
    "accuracy = (results['Predicted class'] == results['True class']).sum() / len(results)\n",
    "# print(f'Accuracy: {accuracy}')\n",
    "\n",
    "pre_0 = ((results['Predicted class'] == 0) & (results['True class'] == 0)).sum() / ((results['True class'] == 0).sum())\n",
    "pre_1 = ((results['Predicted class'] == 1) & (results['True class'] == 1)).sum() / ((results['True class'] == 1).sum())\n",
    "pre_2 = ((results['Predicted class'] == 2) & (results['True class'] == 2)).sum() / ((results['True class'] == 2).sum())\n",
    "pre_3 = +((results['Predicted class'] == 3) & (results['True class'] == 3)).sum() / ((results['True class'] == 3).sum())\n",
    "pre_list = [pre_0, pre_1, pre_2, pre_3]\n",
    "pre_list = [ele for ele in pre_list if not math.isnan(ele)]\n",
    "precision = sum(pre_list) / len(pre_list)\n",
    "# print(f'Precision: {precision}')\n",
    "\n",
    "recall_0 = (results['Predicted class'] == 0).sum() / ((results['True class'] == 0).sum())\n",
    "recall_1 = (results['Predicted class'] == 1).sum() / ((results['True class'] == 1).sum())\n",
    "recall_2 = (results['Predicted class'] == 2).sum() / ((results['True class'] == 2).sum())\n",
    "recall_3 = (results['Predicted class'] == 3).sum() / ((results['True class'] == 3).sum())\n",
    "recall_list = [recall_0, recall_1, recall_2, recall_3]\n",
    "recall_list = [ele for ele in recall_list if not math.isnan(ele)]\n",
    "recall = sum(recall_list) / len(recall_list)\n",
    "# print(f'Recall: {recall}')\n",
    "\n",
    "true_positive = (results['Predicted class'] == results['True class']).sum()\n",
    "# print(f'True positive: {true_positive}')\n",
    "\n",
    "sen_0 = ((results['Predicted class'] == 0) & (results['True class'] == 0)).sum() / ((results['True class'] == 0).sum())\n",
    "sen_1 = ((results['Predicted class'] == 1) & (results['True class'] == 1)).sum() / ((results['True class'] == 1).sum())\n",
    "sen_2 = ((results['Predicted class'] == 2) & (results['True class'] == 2)).sum() / ((results['True class'] == 2).sum())\n",
    "sen_3 = ((results['Predicted class'] == 3) & (results['True class'] == 3)).sum() / ((results['True class'] == 3).sum())\n",
    "sen_list = [sen_0, sen_1, sen_2, sen_3]\n",
    "sen_list = [ele for ele in sen_list if not math.isnan(ele)]\n",
    "sensitivity = sum(sen_list) / len(sen_list)\n",
    "# print(f'Sensitivity: {sensitivity}')\n",
    "\n",
    "spec_0 = ((results['Predicted class'] != 0) & (results['True class'] != 0)).sum() / (((results['Predicted class'] != 0) & (results['True class'] != 0)).sum()+((results['Predicted class'] == 0) & (results['True class'] != 0)).sum())\n",
    "spec_1 = ((results['Predicted class'] != 1) & (results['True class'] != 1)).sum() / (((results['Predicted class'] != 1) & (results['True class'] != 1)).sum()+((results['Predicted class'] == 1) & (results['True class'] != 1)).sum())\n",
    "spec_2 = ((results['Predicted class'] != 2) & (results['True class'] != 2)).sum() / (((results['Predicted class'] != 2) & (results['True class'] != 2)).sum()+((results['Predicted class'] == 2) & (results['True class'] != 2)).sum())\n",
    "spec_3 = ((results['Predicted class'] != 3) & (results['True class'] != 3)).sum() / (((results['Predicted class'] != 3) & (results['True class'] != 3)).sum()+ ((results['Predicted class'] == 3) & (results['True class'] != 3)).sum())\n",
    "specificity_list = [spec_0, spec_1, spec_2, spec_3]\n",
    "specificity_list = [ele for ele in specificity_list if not math.isnan(ele)]\n",
    "specificity = sum(specificity_list) / len(specificity_list)\n",
    "# print(f'Specificity: {specificity}')\n",
    "\n",
    "f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "# print(f'F1 Score: {f1_score}')\n",
    "\n",
    "new_data = pd.DataFrame([{'Type': 'Classification', 'model': 'MR1_2', 'Accuracy': accuracy, 'Precision': precision, 'Recall': recall, 'True positive': true_positive, 'Sensitivity': sensitivity, 'Specificity': specificity, 'F1 Score': f1_score}])\n",
    "\n",
    "classification_dataframe = pd.concat([classification_dataframe, new_data], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification MR1_2 test\n",
    "\n",
    "running_loss = 0.0\n",
    "results = []\n",
    "for folder in os.listdir('./test'):\n",
    "    if os.path.isdir('./test' + '/'+folder):\n",
    "        folder_path = './test'+'/'+folder\n",
    "        files = [f for f in os.listdir(folder_path) if f.endswith('.npy') and mode in f and f[0:4] in patients_codes_set]\n",
    "        if folder == 'NonDemented':\n",
    "            label = 0\n",
    "        elif folder == 'VeryMildDemented':\n",
    "            label = 1\n",
    "        elif folder == 'MildDemented':\n",
    "            label = 2\n",
    "        elif folder == 'ModerateDemented':\n",
    "            label = 3\n",
    "        for f in files :\n",
    "            data = np.load(os.path.join(folder_path, f))\n",
    "            code = f[0:4]\n",
    "            y = data_frame[data_frame['ID'].str.contains(code)][['MMSE', 'CDR', 'SES']].to_numpy()\n",
    "            model.eval()\n",
    "            input_tensor = torch.clamp(torch.tensor(data), 0, 1)\n",
    "            outputs = model(input_tensor)\n",
    "            target = torch.tensor([label]).to(device)\n",
    "            loss = criterion(outputs, target)\n",
    "            running_loss += loss.item()\n",
    "            results.append((np.argmax(outputs.detach().numpy()), label))\n",
    "\n",
    "\n",
    "# convert the results to a numpy array\n",
    "results = np.array(results).reshape(-1, 2)\n",
    "results = pd.DataFrame(results, columns=['Predicted class', 'True class'])\n",
    "results.to_csv('test_results/'+mode+'_'+'results_class.csv', index=False)\n",
    "\n",
    "accuracy = (results['Predicted class'] == results['True class']).sum() / len(results)\n",
    "# print(f'Accuracy: {accuracy}')\n",
    "\n",
    "pre_0 = ((results['Predicted class'] == 0) & (results['True class'] == 0)).sum() / ((results['True class'] == 0).sum())\n",
    "pre_1 = ((results['Predicted class'] == 1) & (results['True class'] == 1)).sum() / ((results['True class'] == 1).sum())\n",
    "pre_2 = ((results['Predicted class'] == 2) & (results['True class'] == 2)).sum() / ((results['True class'] == 2).sum())\n",
    "pre_3 = +((results['Predicted class'] == 3) & (results['True class'] == 3)).sum() / ((results['True class'] == 3).sum())\n",
    "pre_list = [pre_0, pre_1, pre_2, pre_3]\n",
    "pre_list = [ele for ele in pre_list if not math.isnan(ele)]\n",
    "precision = sum(pre_list) / len(pre_list)\n",
    "# print(f'Precision: {precision}')\n",
    "\n",
    "recall_0 = (results['Predicted class'] == 0).sum() / ((results['True class'] == 0).sum())\n",
    "recall_1 = (results['Predicted class'] == 1).sum() / ((results['True class'] == 1).sum())\n",
    "recall_2 = (results['Predicted class'] == 2).sum() / ((results['True class'] == 2).sum())\n",
    "recall_3 = (results['Predicted class'] == 3).sum() / ((results['True class'] == 3).sum())\n",
    "recall_list = [recall_0, recall_1, recall_2, recall_3]\n",
    "recall_list = [ele for ele in recall_list if not math.isnan(ele)]\n",
    "recall = sum(recall_list) / len(recall_list)\n",
    "# print(f'Recall: {recall}')\n",
    "\n",
    "true_positive = (results['Predicted class'] == results['True class']).sum()\n",
    "# print(f'True positive: {true_positive}')\n",
    "\n",
    "sen_0 = ((results['Predicted class'] == 0) & (results['True class'] == 0)).sum() / ((results['True class'] == 0).sum())\n",
    "sen_1 = ((results['Predicted class'] == 1) & (results['True class'] == 1)).sum() / ((results['True class'] == 1).sum())\n",
    "sen_2 = ((results['Predicted class'] == 2) & (results['True class'] == 2)).sum() / ((results['True class'] == 2).sum())\n",
    "sen_3 = ((results['Predicted class'] == 3) & (results['True class'] == 3)).sum() / ((results['True class'] == 3).sum())\n",
    "sen_list = [sen_0, sen_1, sen_2, sen_3]\n",
    "sen_list = [ele for ele in sen_list if not math.isnan(ele)]\n",
    "sensitivity = sum(sen_list) / len(sen_list)\n",
    "# print(f'Sensitivity: {sensitivity}')\n",
    "\n",
    "spec_0 = ((results['Predicted class'] != 0) & (results['True class'] != 0)).sum() / (((results['Predicted class'] != 0) & (results['True class'] != 0)).sum()+((results['Predicted class'] == 0) & (results['True class'] != 0)).sum())\n",
    "spec_1 = ((results['Predicted class'] != 1) & (results['True class'] != 1)).sum() / (((results['Predicted class'] != 1) & (results['True class'] != 1)).sum()+((results['Predicted class'] == 1) & (results['True class'] != 1)).sum())\n",
    "spec_2 = ((results['Predicted class'] != 2) & (results['True class'] != 2)).sum() / (((results['Predicted class'] != 2) & (results['True class'] != 2)).sum()+((results['Predicted class'] == 2) & (results['True class'] != 2)).sum())\n",
    "spec_3 = ((results['Predicted class'] != 3) & (results['True class'] != 3)).sum() / (((results['Predicted class'] != 3) & (results['True class'] != 3)).sum()+ ((results['Predicted class'] == 3) & (results['True class'] != 3)).sum())\n",
    "specificity_list = [spec_0, spec_1, spec_2, spec_3]\n",
    "specificity_list = [ele for ele in specificity_list if not math.isnan(ele)]\n",
    "specificity = sum(specificity_list) / len(specificity_list)\n",
    "# print(f'Specificity: {specificity}')\n",
    "\n",
    "f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "# print(f'F1 Score: {f1_score}')\n",
    "\n",
    "new_data = pd.DataFrame([{'Type': 'Classification', 'model': 'MR1_2', 'Accuracy': accuracy, 'Precision': precision, 'Recall': recall, 'True positive': true_positive, 'Sensitivity': sensitivity, 'Specificity': specificity, 'F1 Score': f1_score}])\n",
    "\n",
    "test_classification_dataframe = pd.concat([test_classification_dataframe, new_data], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification MR1_3\n",
    "model = CombinedModel_classfication(vit_model).to(device)\n",
    "model_load_path = 'models/MR1_1_class.pth'\n",
    "model.load_state_dict(torch.load(model_load_path))\n",
    "\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.use_deterministic_algorithms(True)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "mode_list = ['MR1_1', 'MR1_2', 'MR1_3', 'MR1_4']\n",
    "mode = 'MR1_3'\n",
    "\n",
    "for epoch in range(101):\n",
    "    running_loss = 0.0\n",
    "    results = []\n",
    "    for folder in os.listdir('./combined_data'):\n",
    "        if os.path.isdir('./combined_data' + '/'+folder):\n",
    "            folder_path = './combined_data'+'/'+folder\n",
    "            files = [f for f in os.listdir(folder_path) if f.endswith('.npy') and mode in f and f[0:4] in patients_codes_set]\n",
    "            if folder == 'NonDemented':\n",
    "                label = 0\n",
    "            elif folder == 'VeryMildDemented':\n",
    "                label = 1\n",
    "            elif folder == 'MildDemented':\n",
    "                label = 2\n",
    "            elif folder == 'ModerateDemented':\n",
    "                label = 3\n",
    "            for f in files :\n",
    "                data = np.load(os.path.join(folder_path, f))\n",
    "                code = f[0:4]\n",
    "                y = data_frame[data_frame['ID'].str.contains(code)][['MMSE', 'CDR', 'SES']].to_numpy()\n",
    "                model.train()\n",
    "                optimizer.zero_grad()\n",
    "                input_tensor = torch.clamp(torch.tensor(data), 0, 1)\n",
    "                outputs = model(input_tensor)\n",
    "                target = torch.tensor([label]).to(device)\n",
    "                loss = criterion(outputs, target)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                running_loss += loss.item()\n",
    "                results.append((np.argmax(outputs.detach().numpy()), label))\n",
    "    if epoch == 100:\n",
    "        print(f'Epoch {epoch} loss: {running_loss}')\n",
    "\n",
    "# convert the results to a numpy array\n",
    "results = np.array(results).reshape(-1, 2)\n",
    "results = pd.DataFrame(results, columns=['Predicted class', 'True class'])\n",
    "results.to_csv('results/'+mode+'_'+'results_class.csv', index=False)\n",
    "\n",
    "model_save_path = 'models/'+mode+'_'+'class.pth'\n",
    "torch.save(model.state_dict(), model_save_path)\n",
    "print(f\"Model saved to {model_save_path}\")\n",
    "\n",
    "model_test = CombinedModel(vit_model)\n",
    "\n",
    "# Load the model state\n",
    "# model_load_path = model_save_path\n",
    "# model.load_state_dict(torch.load(model_load_path))\n",
    "# model.eval()  # Set the model to evaluation mode\n",
    "# print(f\"Model loaded from {model_load_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding MR1_3 results to the dataframe\n",
    "\n",
    "accuracy = (results['Predicted class'] == results['True class']).sum() / len(results)\n",
    "# print(f'Accuracy: {accuracy}')\n",
    "\n",
    "pre_0 = ((results['Predicted class'] == 0) & (results['True class'] == 0)).sum() / ((results['True class'] == 0).sum())\n",
    "pre_1 = ((results['Predicted class'] == 1) & (results['True class'] == 1)).sum() / ((results['True class'] == 1).sum())\n",
    "pre_2 = ((results['Predicted class'] == 2) & (results['True class'] == 2)).sum() / ((results['True class'] == 2).sum())\n",
    "pre_3 = +((results['Predicted class'] == 3) & (results['True class'] == 3)).sum() / ((results['True class'] == 3).sum())\n",
    "pre_list = [pre_0, pre_1, pre_2, pre_3]\n",
    "pre_list = [ele for ele in pre_list if not math.isnan(ele)]\n",
    "precision = sum(pre_list) / len(pre_list)\n",
    "# print(f'Precision: {precision}')\n",
    "\n",
    "recall_0 = (results['Predicted class'] == 0).sum() / ((results['True class'] == 0).sum())\n",
    "recall_1 = (results['Predicted class'] == 1).sum() / ((results['True class'] == 1).sum())\n",
    "recall_2 = (results['Predicted class'] == 2).sum() / ((results['True class'] == 2).sum())\n",
    "recall_3 = (results['Predicted class'] == 3).sum() / ((results['True class'] == 3).sum())\n",
    "recall_list = [recall_0, recall_1, recall_2, recall_3]\n",
    "recall_list = [ele for ele in recall_list if not math.isnan(ele)]\n",
    "recall = sum(recall_list) / len(recall_list)\n",
    "# print(f'Recall: {recall}')\n",
    "\n",
    "true_positive = (results['Predicted class'] == results['True class']).sum()\n",
    "# print(f'True positive: {true_positive}')\n",
    "\n",
    "sen_0 = ((results['Predicted class'] == 0) & (results['True class'] == 0)).sum() / ((results['True class'] == 0).sum())\n",
    "sen_1 = ((results['Predicted class'] == 1) & (results['True class'] == 1)).sum() / ((results['True class'] == 1).sum())\n",
    "sen_2 = ((results['Predicted class'] == 2) & (results['True class'] == 2)).sum() / ((results['True class'] == 2).sum())\n",
    "sen_3 = ((results['Predicted class'] == 3) & (results['True class'] == 3)).sum() / ((results['True class'] == 3).sum())\n",
    "sen_list = [sen_0, sen_1, sen_2, sen_3]\n",
    "sen_list = [ele for ele in sen_list if not math.isnan(ele)]\n",
    "sensitivity = sum(sen_list) / len(sen_list)\n",
    "# print(f'Sensitivity: {sensitivity}')\n",
    "\n",
    "spec_0 = ((results['Predicted class'] != 0) & (results['True class'] != 0)).sum() / (((results['Predicted class'] != 0) & (results['True class'] != 0)).sum()+((results['Predicted class'] == 0) & (results['True class'] != 0)).sum())\n",
    "spec_1 = ((results['Predicted class'] != 1) & (results['True class'] != 1)).sum() / (((results['Predicted class'] != 1) & (results['True class'] != 1)).sum()+((results['Predicted class'] == 1) & (results['True class'] != 1)).sum())\n",
    "spec_2 = ((results['Predicted class'] != 2) & (results['True class'] != 2)).sum() / (((results['Predicted class'] != 2) & (results['True class'] != 2)).sum()+((results['Predicted class'] == 2) & (results['True class'] != 2)).sum())\n",
    "spec_3 = ((results['Predicted class'] != 3) & (results['True class'] != 3)).sum() / (((results['Predicted class'] != 3) & (results['True class'] != 3)).sum()+ ((results['Predicted class'] == 3) & (results['True class'] != 3)).sum())\n",
    "specificity_list = [spec_0, spec_1, spec_2, spec_3]\n",
    "specificity_list = [ele for ele in specificity_list if not math.isnan(ele)]\n",
    "specificity = sum(specificity_list) / len(specificity_list)\n",
    "# print(f'Specificity: {specificity}')\n",
    "\n",
    "f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "# print(f'F1 Score: {f1_score}')\n",
    "\n",
    "new_data = pd.DataFrame([{'Type': 'Classification', 'model': 'MR1_3', 'Accuracy': accuracy, 'Precision': precision, 'Recall': recall, 'True positive': true_positive, 'Sensitivity': sensitivity, 'Specificity': specificity, 'F1 Score': f1_score}])\n",
    "\n",
    "classification_dataframe = pd.concat([classification_dataframe, new_data], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification MR1_3 test\n",
    "\n",
    "running_loss = 0.0\n",
    "results = []\n",
    "for folder in os.listdir('./test'):\n",
    "    if os.path.isdir('./test' + '/'+folder):\n",
    "        folder_path = './test'+'/'+folder\n",
    "        files = [f for f in os.listdir(folder_path) if f.endswith('.npy') and mode in f and f[0:4] in patients_codes_set]\n",
    "        if folder == 'NonDemented':\n",
    "            label = 0\n",
    "        elif folder == 'VeryMildDemented':\n",
    "            label = 1\n",
    "        elif folder == 'MildDemented':\n",
    "            label = 2\n",
    "        elif folder == 'ModerateDemented':\n",
    "            label = 3\n",
    "        for f in files :\n",
    "            data = np.load(os.path.join(folder_path, f))\n",
    "            code = f[0:4]\n",
    "            y = data_frame[data_frame['ID'].str.contains(code)][['MMSE', 'CDR', 'SES']].to_numpy()\n",
    "            model.eval()\n",
    "            input_tensor = torch.clamp(torch.tensor(data), 0, 1)\n",
    "            outputs = model(input_tensor)\n",
    "            target = torch.tensor([label]).to(device)\n",
    "            loss = criterion(outputs, target)\n",
    "            running_loss += loss.item()\n",
    "            results.append((np.argmax(outputs.detach().numpy()), label))\n",
    "\n",
    "\n",
    "# convert the results to a numpy array\n",
    "results = np.array(results).reshape(-1, 2)\n",
    "results = pd.DataFrame(results, columns=['Predicted class', 'True class'])\n",
    "results.to_csv('test_results/'+mode+'_'+'results_class.csv', index=False)\n",
    "\n",
    "accuracy = (results['Predicted class'] == results['True class']).sum() / len(results)\n",
    "# print(f'Accuracy: {accuracy}')\n",
    "\n",
    "pre_0 = ((results['Predicted class'] == 0) & (results['True class'] == 0)).sum() / ((results['True class'] == 0).sum())\n",
    "pre_1 = ((results['Predicted class'] == 1) & (results['True class'] == 1)).sum() / ((results['True class'] == 1).sum())\n",
    "pre_2 = ((results['Predicted class'] == 2) & (results['True class'] == 2)).sum() / ((results['True class'] == 2).sum())\n",
    "pre_3 = +((results['Predicted class'] == 3) & (results['True class'] == 3)).sum() / ((results['True class'] == 3).sum())\n",
    "pre_list = [pre_0, pre_1, pre_2, pre_3]\n",
    "pre_list = [ele for ele in pre_list if not math.isnan(ele)]\n",
    "precision = sum(pre_list) / len(pre_list)\n",
    "# print(f'Precision: {precision}')\n",
    "\n",
    "recall_0 = (results['Predicted class'] == 0).sum() / ((results['True class'] == 0).sum())\n",
    "recall_1 = (results['Predicted class'] == 1).sum() / ((results['True class'] == 1).sum())\n",
    "recall_2 = (results['Predicted class'] == 2).sum() / ((results['True class'] == 2).sum())\n",
    "recall_3 = (results['Predicted class'] == 3).sum() / ((results['True class'] == 3).sum())\n",
    "recall_list = [recall_0, recall_1, recall_2, recall_3]\n",
    "recall_list = [ele for ele in recall_list if not math.isnan(ele)]\n",
    "recall = sum(recall_list) / len(recall_list)\n",
    "# print(f'Recall: {recall}')\n",
    "\n",
    "true_positive = (results['Predicted class'] == results['True class']).sum()\n",
    "# print(f'True positive: {true_positive}')\n",
    "\n",
    "sen_0 = ((results['Predicted class'] == 0) & (results['True class'] == 0)).sum() / ((results['True class'] == 0).sum())\n",
    "sen_1 = ((results['Predicted class'] == 1) & (results['True class'] == 1)).sum() / ((results['True class'] == 1).sum())\n",
    "sen_2 = ((results['Predicted class'] == 2) & (results['True class'] == 2)).sum() / ((results['True class'] == 2).sum())\n",
    "sen_3 = ((results['Predicted class'] == 3) & (results['True class'] == 3)).sum() / ((results['True class'] == 3).sum())\n",
    "sen_list = [sen_0, sen_1, sen_2, sen_3]\n",
    "sen_list = [ele for ele in sen_list if not math.isnan(ele)]\n",
    "sensitivity = sum(sen_list) / len(sen_list)\n",
    "# print(f'Sensitivity: {sensitivity}')\n",
    "\n",
    "spec_0 = ((results['Predicted class'] != 0) & (results['True class'] != 0)).sum() / (((results['Predicted class'] != 0) & (results['True class'] != 0)).sum()+((results['Predicted class'] == 0) & (results['True class'] != 0)).sum())\n",
    "spec_1 = ((results['Predicted class'] != 1) & (results['True class'] != 1)).sum() / (((results['Predicted class'] != 1) & (results['True class'] != 1)).sum()+((results['Predicted class'] == 1) & (results['True class'] != 1)).sum())\n",
    "spec_2 = ((results['Predicted class'] != 2) & (results['True class'] != 2)).sum() / (((results['Predicted class'] != 2) & (results['True class'] != 2)).sum()+((results['Predicted class'] == 2) & (results['True class'] != 2)).sum())\n",
    "spec_3 = ((results['Predicted class'] != 3) & (results['True class'] != 3)).sum() / (((results['Predicted class'] != 3) & (results['True class'] != 3)).sum()+ ((results['Predicted class'] == 3) & (results['True class'] != 3)).sum())\n",
    "specificity_list = [spec_0, spec_1, spec_2, spec_3]\n",
    "specificity_list = [ele for ele in specificity_list if not math.isnan(ele)]\n",
    "specificity = sum(specificity_list) / len(specificity_list)\n",
    "# print(f'Specificity: {specificity}')\n",
    "\n",
    "f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "# print(f'F1 Score: {f1_score}')\n",
    "\n",
    "new_data = pd.DataFrame([{'Type': 'Classification', 'model': 'MR1_3', 'Accuracy': accuracy, 'Precision': precision, 'Recall': recall, 'True positive': true_positive, 'Sensitivity': sensitivity, 'Specificity': specificity, 'F1 Score': f1_score}])\n",
    "\n",
    "test_classification_dataframe = pd.concat([test_classification_dataframe, new_data], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification MR1_4\n",
    "model = CombinedModel_classfication(vit_model).to(device)\n",
    "model_load_path = 'models/MR1_1_class.pth'\n",
    "model.load_state_dict(torch.load(model_load_path))\n",
    "\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.use_deterministic_algorithms(True)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "mode_list = ['MR1_1', 'MR1_2', 'MR1_3', 'MR1_4']\n",
    "mode = 'MR1_4'\n",
    "\n",
    "for epoch in range(101):\n",
    "    running_loss = 0.0\n",
    "    results = []\n",
    "    for folder in os.listdir('./combined_data'):\n",
    "        if os.path.isdir('./combined_data' + '/'+folder):\n",
    "            folder_path = './combined_data'+'/'+folder\n",
    "            files = [f for f in os.listdir(folder_path) if f.endswith('.npy') and mode in f and f[0:4] in patients_codes_set]\n",
    "            if folder == 'NonDemented':\n",
    "                label = 0\n",
    "            elif folder == 'VeryMildDemented':\n",
    "                label = 1\n",
    "            elif folder == 'MildDemented':\n",
    "                label = 2\n",
    "            elif folder == 'ModerateDemented':\n",
    "                label = 3\n",
    "            for f in files :\n",
    "                data = np.load(os.path.join(folder_path, f))\n",
    "                code = f[0:4]\n",
    "                y = data_frame[data_frame['ID'].str.contains(code)][['MMSE', 'CDR', 'SES']].to_numpy()\n",
    "                model.train()\n",
    "                optimizer.zero_grad()\n",
    "                input_tensor = torch.clamp(torch.tensor(data), 0, 1)\n",
    "                outputs = model(input_tensor)\n",
    "                target = torch.tensor([label]).to(device)\n",
    "                loss = criterion(outputs, target)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                running_loss += loss.item()\n",
    "                results.append((np.argmax(outputs.detach().numpy()), label))\n",
    "    if epoch == 100:\n",
    "        print(f'Epoch {epoch} loss: {running_loss}')\n",
    "\n",
    "# convert the results to a numpy array\n",
    "results = np.array(results).reshape(-1, 2)\n",
    "results = pd.DataFrame(results, columns=['Predicted class', 'True class'])\n",
    "results.to_csv('results/'+mode+'_'+'results_class.csv', index=False)\n",
    "\n",
    "model_save_path = 'models/'+mode+'_'+'class.pth'\n",
    "torch.save(model.state_dict(), model_save_path)\n",
    "print(f\"Model saved to {model_save_path}\")\n",
    "\n",
    "model_test = CombinedModel(vit_model)\n",
    "\n",
    "# Load the model state\n",
    "# model_load_path = model_save_path\n",
    "# model.load_state_dict(torch.load(model_load_path))\n",
    "# model.eval()  # Set the model to evaluation mode\n",
    "# print(f\"Model loaded from {model_load_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding MR1_4 results to the dataframe\n",
    "\n",
    "accuracy = (results['Predicted class'] == results['True class']).sum() / len(results)\n",
    "# print(f'Accuracy: {accuracy}')\n",
    "\n",
    "pre_0 = ((results['Predicted class'] == 0) & (results['True class'] == 0)).sum() / ((results['True class'] == 0).sum())\n",
    "pre_1 = ((results['Predicted class'] == 1) & (results['True class'] == 1)).sum() / ((results['True class'] == 1).sum())\n",
    "pre_2 = ((results['Predicted class'] == 2) & (results['True class'] == 2)).sum() / ((results['True class'] == 2).sum())\n",
    "pre_3 = +((results['Predicted class'] == 3) & (results['True class'] == 3)).sum() / ((results['True class'] == 3).sum())\n",
    "pre_list = [pre_0, pre_1, pre_2, pre_3]\n",
    "pre_list = [ele for ele in pre_list if not math.isnan(ele)]\n",
    "precision = sum(pre_list) / len(pre_list)\n",
    "# print(f'Precision: {precision}')\n",
    "\n",
    "recall_0 = (results['Predicted class'] == 0).sum() / ((results['True class'] == 0).sum())\n",
    "recall_1 = (results['Predicted class'] == 1).sum() / ((results['True class'] == 1).sum())\n",
    "recall_2 = (results['Predicted class'] == 2).sum() / ((results['True class'] == 2).sum())\n",
    "recall_3 = (results['Predicted class'] == 3).sum() / ((results['True class'] == 3).sum())\n",
    "recall_list = [recall_0, recall_1, recall_2, recall_3]\n",
    "recall_list = [ele for ele in recall_list if not math.isnan(ele)]\n",
    "recall = sum(recall_list) / len(recall_list)\n",
    "# print(f'Recall: {recall}')\n",
    "\n",
    "true_positive = (results['Predicted class'] == results['True class']).sum()\n",
    "# print(f'True positive: {true_positive}')\n",
    "\n",
    "sen_0 = ((results['Predicted class'] == 0) & (results['True class'] == 0)).sum() / ((results['True class'] == 0).sum())\n",
    "sen_1 = ((results['Predicted class'] == 1) & (results['True class'] == 1)).sum() / ((results['True class'] == 1).sum())\n",
    "sen_2 = ((results['Predicted class'] == 2) & (results['True class'] == 2)).sum() / ((results['True class'] == 2).sum())\n",
    "sen_3 = ((results['Predicted class'] == 3) & (results['True class'] == 3)).sum() / ((results['True class'] == 3).sum())\n",
    "sen_list = [sen_0, sen_1, sen_2, sen_3]\n",
    "sen_list = [ele for ele in sen_list if not math.isnan(ele)]\n",
    "sensitivity = sum(sen_list) / len(sen_list)\n",
    "# print(f'Sensitivity: {sensitivity}')\n",
    "\n",
    "spec_0 = ((results['Predicted class'] != 0) & (results['True class'] != 0)).sum() / (((results['Predicted class'] != 0) & (results['True class'] != 0)).sum()+((results['Predicted class'] == 0) & (results['True class'] != 0)).sum())\n",
    "spec_1 = ((results['Predicted class'] != 1) & (results['True class'] != 1)).sum() / (((results['Predicted class'] != 1) & (results['True class'] != 1)).sum()+((results['Predicted class'] == 1) & (results['True class'] != 1)).sum())\n",
    "spec_2 = ((results['Predicted class'] != 2) & (results['True class'] != 2)).sum() / (((results['Predicted class'] != 2) & (results['True class'] != 2)).sum()+((results['Predicted class'] == 2) & (results['True class'] != 2)).sum())\n",
    "spec_3 = ((results['Predicted class'] != 3) & (results['True class'] != 3)).sum() / (((results['Predicted class'] != 3) & (results['True class'] != 3)).sum()+ ((results['Predicted class'] == 3) & (results['True class'] != 3)).sum())\n",
    "specificity_list = [spec_0, spec_1, spec_2, spec_3]\n",
    "specificity_list = [ele for ele in specificity_list if not math.isnan(ele)]\n",
    "specificity = sum(specificity_list) / len(specificity_list)\n",
    "# print(f'Specificity: {specificity}')\n",
    "\n",
    "f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "# print(f'F1 Score: {f1_score}')\n",
    "\n",
    "new_data = pd.DataFrame([{'Type': 'Classification', 'model': 'MR1_4', 'Accuracy': accuracy, 'Precision': precision, 'Recall': recall, 'True positive': true_positive, 'Sensitivity': sensitivity, 'Specificity': specificity, 'F1 Score': f1_score}])\n",
    "\n",
    "classification_dataframe = pd.concat([classification_dataframe, new_data], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification MR1_4 test\n",
    "\n",
    "running_loss = 0.0\n",
    "results = []\n",
    "for folder in os.listdir('./test'):\n",
    "    if os.path.isdir('./test' + '/'+folder):\n",
    "        folder_path = './test'+'/'+folder\n",
    "        files = [f for f in os.listdir(folder_path) if f.endswith('.npy') and mode in f and f[0:4] in patients_codes_set]\n",
    "        if folder == 'NonDemented':\n",
    "            label = 0\n",
    "        elif folder == 'VeryMildDemented':\n",
    "            label = 1\n",
    "        elif folder == 'MildDemented':\n",
    "            label = 2\n",
    "        elif folder == 'ModerateDemented':\n",
    "            label = 3\n",
    "        for f in files :\n",
    "            data = np.load(os.path.join(folder_path, f))\n",
    "            code = f[0:4]\n",
    "            y = data_frame[data_frame['ID'].str.contains(code)][['MMSE', 'CDR', 'SES']].to_numpy()\n",
    "            model.eval()\n",
    "            input_tensor = torch.clamp(torch.tensor(data), 0, 1)\n",
    "            outputs = model(input_tensor)\n",
    "            target = torch.tensor([label]).to(device)\n",
    "            loss = criterion(outputs, target)\n",
    "            running_loss += loss.item()\n",
    "            results.append((np.argmax(outputs.detach().numpy()), label))\n",
    "\n",
    "\n",
    "# convert the results to a numpy array\n",
    "results = np.array(results).reshape(-1, 2)\n",
    "results = pd.DataFrame(results, columns=['Predicted class', 'True class'])\n",
    "results.to_csv('test_results/'+mode+'_'+'results_class.csv', index=False)\n",
    "\n",
    "accuracy = (results['Predicted class'] == results['True class']).sum() / len(results)\n",
    "# print(f'Accuracy: {accuracy}')\n",
    "\n",
    "pre_0 = ((results['Predicted class'] == 0) & (results['True class'] == 0)).sum() / ((results['True class'] == 0).sum())\n",
    "pre_1 = ((results['Predicted class'] == 1) & (results['True class'] == 1)).sum() / ((results['True class'] == 1).sum())\n",
    "pre_2 = ((results['Predicted class'] == 2) & (results['True class'] == 2)).sum() / ((results['True class'] == 2).sum())\n",
    "pre_3 = +((results['Predicted class'] == 3) & (results['True class'] == 3)).sum() / ((results['True class'] == 3).sum())\n",
    "pre_list = [pre_0, pre_1, pre_2, pre_3]\n",
    "pre_list = [ele for ele in pre_list if not math.isnan(ele)]\n",
    "precision = sum(pre_list) / len(pre_list)\n",
    "# print(f'Precision: {precision}')\n",
    "\n",
    "recall_0 = (results['Predicted class'] == 0).sum() / ((results['True class'] == 0).sum())\n",
    "recall_1 = (results['Predicted class'] == 1).sum() / ((results['True class'] == 1).sum())\n",
    "recall_2 = (results['Predicted class'] == 2).sum() / ((results['True class'] == 2).sum())\n",
    "recall_3 = (results['Predicted class'] == 3).sum() / ((results['True class'] == 3).sum())\n",
    "recall_list = [recall_0, recall_1, recall_2, recall_3]\n",
    "recall_list = [ele for ele in recall_list if not math.isnan(ele)]\n",
    "recall = sum(recall_list) / len(recall_list)\n",
    "# print(f'Recall: {recall}')\n",
    "\n",
    "true_positive = (results['Predicted class'] == results['True class']).sum()\n",
    "# print(f'True positive: {true_positive}')\n",
    "\n",
    "sen_0 = ((results['Predicted class'] == 0) & (results['True class'] == 0)).sum() / ((results['True class'] == 0).sum())\n",
    "sen_1 = ((results['Predicted class'] == 1) & (results['True class'] == 1)).sum() / ((results['True class'] == 1).sum())\n",
    "sen_2 = ((results['Predicted class'] == 2) & (results['True class'] == 2)).sum() / ((results['True class'] == 2).sum())\n",
    "sen_3 = ((results['Predicted class'] == 3) & (results['True class'] == 3)).sum() / ((results['True class'] == 3).sum())\n",
    "sen_list = [sen_0, sen_1, sen_2, sen_3]\n",
    "sen_list = [ele for ele in sen_list if not math.isnan(ele)]\n",
    "sensitivity = sum(sen_list) / len(sen_list)\n",
    "# print(f'Sensitivity: {sensitivity}')\n",
    "\n",
    "spec_0 = ((results['Predicted class'] != 0) & (results['True class'] != 0)).sum() / (((results['Predicted class'] != 0) & (results['True class'] != 0)).sum()+((results['Predicted class'] == 0) & (results['True class'] != 0)).sum())\n",
    "spec_1 = ((results['Predicted class'] != 1) & (results['True class'] != 1)).sum() / (((results['Predicted class'] != 1) & (results['True class'] != 1)).sum()+((results['Predicted class'] == 1) & (results['True class'] != 1)).sum())\n",
    "spec_2 = ((results['Predicted class'] != 2) & (results['True class'] != 2)).sum() / (((results['Predicted class'] != 2) & (results['True class'] != 2)).sum()+((results['Predicted class'] == 2) & (results['True class'] != 2)).sum())\n",
    "spec_3 = ((results['Predicted class'] != 3) & (results['True class'] != 3)).sum() / (((results['Predicted class'] != 3) & (results['True class'] != 3)).sum()+ ((results['Predicted class'] == 3) & (results['True class'] != 3)).sum())\n",
    "specificity_list = [spec_0, spec_1, spec_2, spec_3]\n",
    "specificity_list = [ele for ele in specificity_list if not math.isnan(ele)]\n",
    "specificity = sum(specificity_list) / len(specificity_list)\n",
    "# print(f'Specificity: {specificity}')\n",
    "\n",
    "f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "# print(f'F1 Score: {f1_score}')\n",
    "\n",
    "new_data = pd.DataFrame([{'Type': 'Classification', 'model': 'MR1_4', 'Accuracy': accuracy, 'Precision': precision, 'Recall': recall, 'True positive': true_positive, 'Sensitivity': sensitivity, 'Specificity': specificity, 'F1 Score': f1_score}])\n",
    "\n",
    "test_classification_dataframe = pd.concat([test_classification_dataframe, new_data], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_dataframe.to_csv('results/regression_results.csv', index=False)\n",
    "classification_dataframe.to_csv('results/classification_results.csv', index=False)\n",
    "test_regression_dataframe.to_csv('test_results/test_regression_results.csv', index=False)\n",
    "test_classification_dataframe.to_csv('test_results/test_classification_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_path = 'original_data/MildDemented/OAS1_0028_MR1_1.nii_slice_113.png'\n",
    "# image = Image.open(image_path)\n",
    "# img_array = np.array(image)\n",
    "# img_array = img_array[:, :, :3] / 255.0\n",
    "# img_array = torch.tensor(img_array).permute(2, 0, 1)\n",
    "# y = feature_extractor(images=img_array, return_tensors=\"pt\")['pixel_values'].squeeze()\n",
    "# plt.imshow(img_array[0, :, :], cmap='gray')\n",
    "# plt.show()\n",
    "# plt.imshow(y[2, :, :], cmap='gray')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# intermediate_outputs = []\n",
    "\n",
    "# def hook(module, input, output):\n",
    "#     intermediate_outputs.append(output)\n",
    "# # Register the hook\n",
    "# hook_handle = model.vit_model.encoder.layer[0].output.register_forward_hook(hook)\n",
    "\n",
    "# # Get the final output\n",
    "# final_output = model(img_array)\n",
    "\n",
    "# # Remove the hook\n",
    "# hook_handle.remove()\n",
    "\n",
    "# print(\"Final output shape:\", final_output.shape)\n",
    "# print(\"Intermediate output shape:\", intermediate_outputs[0].shape)\n",
    "# plt.imshow(intermediate_outputs[0][0, :, :].detach().numpy(), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet18(pretrained=True)\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 4)\n",
    "\n",
    "running_loss = 0.0\n",
    "results = []\n",
    "for folder in os.listdir('./test'):\n",
    "    if os.path.isdir('./test' + '/'+folder):\n",
    "        folder_path = './test'+'/'+folder\n",
    "        files = [f for f in os.listdir(folder_path) if f.endswith('.npy') and mode in f and f[0:4] in patients_codes_set]\n",
    "        if folder == 'NonDemented':\n",
    "            label = 0\n",
    "        elif folder == 'VeryMildDemented':\n",
    "            label = 1\n",
    "        elif folder == 'MildDemented':\n",
    "            label = 2\n",
    "        elif folder == 'ModerateDemented':\n",
    "            label = 3\n",
    "        for f in files :\n",
    "            data = np.load(os.path.join(folder_path, f))\n",
    "            code = f[0:4]\n",
    "            y = data_frame[data_frame['ID'].str.contains(code)][['MMSE', 'CDR', 'SES']].to_numpy()\n",
    "            model.eval()\n",
    "            input_tensor = torch.clamp(torch.tensor(data), 0, 1)\n",
    "            outputs = model(input_tensor)\n",
    "            target = torch.tensor([label]).to(device)\n",
    "            loss = criterion(outputs, target)\n",
    "            running_loss += loss.item()\n",
    "            results.append((np.argmax(outputs.detach().numpy()), label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cancer_immune_jupyter",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
